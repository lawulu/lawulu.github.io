<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>璐濒殉漂流记</title>
    <link>https://lawulu.github.io/tags/scala/feed/index.xml</link>
    <description>Recent content on 璐濒殉漂流记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <atom:link href="https://lawulu.github.io/tags/scala/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Transform技术选型：Spark Structured Streaming Vs Pure Scala</title>
      <link>https://lawulu.github.io/post/Transform%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%EF%BC%9ASpark%20Vs%20Scala/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Transform%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%EF%BC%9ASpark%20Vs%20Scala/</guid>
      <description>

&lt;h2 id=&#34;需求&#34;&gt;需求&lt;/h2&gt;

&lt;p&gt;公司要上实时，需要一个应用对原始日志进行转换，简单来说：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从Kafka读取数据，然后写回到Kafka&lt;/li&gt;
&lt;li&gt;对日志和数据进行合并&lt;/li&gt;
&lt;li&gt;完成归因、去重、真实点击等其他需求&lt;/li&gt;
&lt;li&gt;完成计费&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;有这么几个技术需求：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Json的处理，FileBeat产生的In和Druid需要的Out都是Json形式。&lt;/li&gt;
&lt;li&gt;Kafka读写&lt;/li&gt;
&lt;li&gt;外部数据源，Mysql，Redis和MongoDB的读取&lt;/li&gt;
&lt;li&gt;逻辑处理&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;spark-or-scala&#34;&gt;Spark or Scala&lt;/h2&gt;

&lt;p&gt;所谓的Spark，即Spark Structured Streaming，所谓的Scala是Scala based on Play Framework
优先考虑的是Spark（Spark Structured Streaming），因为Spark可以做流处理和即席查询，某种程度上可以复用很多逻辑，并且可以接入Hive-serde表，与无缝与Hive切换。&lt;/p&gt;

&lt;h3 id=&#34;技术需求&#34;&gt;技术需求&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Json

&lt;ul&gt;
&lt;li&gt;Spark：问题不大，但需要调研，Scala貌似没什么好用的Json库&lt;/li&gt;
&lt;li&gt;Scala：Play自带Json库&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Kafka

&lt;ul&gt;
&lt;li&gt;Spark：官方提供有类库，但是屏蔽的细节太多了。现在项目内没人清楚DStream/Spark.readStream是怎么个机制&lt;/li&gt;
&lt;li&gt;Scala：Kafka官方的Client是Java的，Akka Stream有对应的封装。如果不能用，解决起来也比较方便&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;外部DB

&lt;ul&gt;
&lt;li&gt;Spark：问题不大，需要调研如果精细的控制Partiton与连接之间的关系，还有Lookup问题&lt;/li&gt;
&lt;li&gt;Scala：Scala有各种Reactive的驱动&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;非技术需求&#34;&gt;非技术需求&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;监控&amp;amp;日志

&lt;ul&gt;
&lt;li&gt;用Spark的话，现有公司/阿里云的各种基础设施很难用的上&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;补数，关键是对Kafka的Offset做精细的控制

&lt;ul&gt;
&lt;li&gt;搜了一下，Spark这块放到Checkpoint了&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TroubleShooting

&lt;ul&gt;
&lt;li&gt;Spark：？？？公司现在并没有用Spark跑大规模的应用&lt;/li&gt;
&lt;li&gt;Scala：Akka这块&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;

&lt;p&gt;所谓Spark的优势：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以RDD/DataFrame/SQL形式提供的对数据处理的DSL，虽然比Hive效率更高，可以和Scala程序同时工作&lt;/li&gt;
&lt;li&gt;横向扩展以及容错&lt;/li&gt;
&lt;li&gt;Broadcast/Accumulator等原语&lt;/li&gt;
&lt;li&gt;可以有效利用HDFS对应的计算资源，并且做为一个Unified的平台，理论上可以重用很多逻辑&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Spark的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Structured Streaming API 不稳定，我自己测试发现有Job莫名奇妙不运行的情况。&lt;/li&gt;
&lt;li&gt;任务调度和执行都是黑盒&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Spark并不是银弹，更倾向于用纯Java应用来做。Spark的优势在一个纯Transform的应用里面发挥不出来（上面三点：1显然不如直接写程序，对于2瓶颈在Kafka，3引入Redis可以解决类似问题。
）。后续可以研究一下Kafka Streams。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>使用Scala开发自己的DSL</title>
      <link>https://lawulu.github.io/post/%E4%BD%BF%E7%94%A8Scala%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84DSL/</link>
      <pubDate>Thu, 20 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E4%BD%BF%E7%94%A8Scala%E5%BC%80%E5%8F%91%E8%87%AA%E5%B7%B1%E7%9A%84DSL/</guid>
      <description>

&lt;h2 id=&#34;scala为什么适合dsl&#34;&gt;Scala为什么适合DSL&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;对于一个参数的方法可以省略点/括号&lt;/li&gt;
&lt;li&gt;可以使用特殊符号做方法&lt;/li&gt;
&lt;li&gt;函数式编程&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>