<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post-rsses on 璐濒殉漂流记</title>
    <link>https://lawulu.github.io/post/feed/index.xml</link>
    <description>Recent content in Post-rsses on 璐濒殉漂流记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Fri, 15 Dec 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://lawulu.github.io/post/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>小陈与大数据的故事</title>
      <link>https://lawulu.github.io/post/%E5%B0%8F%E9%99%88%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%85%E4%BA%8B/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E5%B0%8F%E9%99%88%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%85%E4%BA%8B/</guid>
      <description>

&lt;p&gt;&lt;em&gt;本篇为公众号&lt;code&gt;码农翻身&lt;/code&gt;的约稿&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;在学校&#34;&gt;在学校&lt;/h2&gt;

&lt;p&gt;做为一个科班出身的程序员，在小陈还不明白自己所学的的数据结构和操作系统这些专业课跟未来的工作有什么关系，甚至未来做什么也不清楚时候，小陈最喜欢做的事就是看电影，看完还舍不得删。那个时代流行的还是“为人不识武藤兰，阅遍电影也枉然”，电影还有很多是rm格式的，几百兆都算大的，但是架不住小陈对一衣带水邻国文化的热爱，只有120G的硬盘让他很快有了另一个爱好：整理硬盘，每次有新资源出来，小陈都得想办法腾点空间出来。&lt;/p&gt;

&lt;p&gt;后来教育网里一个叫Maze的软件在我校流行开来，这个软件可以在局域网内以P2P的方式完成资源共享。喜大普奔，小陈得意洋洋的宣布自己终于不用整理硬盘了，自己硬盘里面只存一部分经典的，想看什么电影从别人机器里面拖，哪怕自己临时要看一个美帝大片，删掉一部分电影，删掉之后都还能从别人机器里面拖回来。&lt;/p&gt;

&lt;p&gt;直到有一天，小陈临时删了一位老师的代表作，等想找回来时候，不知道是学校调整了网络路由还是因为高年级学生的离校，这部本来在Maze中非常常见的电影居然一个都找不到了。小陈被室友嘲笑之余，怒而卸载了Maze，并决定要开发一套更好的共享资源软件：要有一个元数据服务器，所有使用者的硬盘的读写都由元数据服务器来管理，元数据保证每份电影都至少存在2份以上，而不是像现在这样保存什么电影，全靠用户心照不宣的默契和自己的兴趣。&lt;/p&gt;

&lt;p&gt;不过小陈也面临着毕业，自然没有时间去搞这些乱七八糟的东西，为了找工作，开始恶补各种技能。这已经是2011年，大数据已经开始火起来了，小陈开始试着学习大数据的知识。搞Android培训的那波人摇身一变开始培训Hadoop了，小陈上了一次试听课之后，回来开始向室友生成，自己的创意被Google和Hadoop给剽窃了！大数据首先要解决的都是存储问问题，GFS，以及受之启发的Hadoop HDFS，完全就是照着自己的资源共享软件思路来的。&lt;/p&gt;

&lt;p&gt;其实小陈知道，Google在2003年就把GFS的论文给写出来，开发这个GFS时候武老师可能还没有出道，甚至BigData这个词还没有被清楚的定义。但是Google作为技术最领先，体量最大的搜索引擎公司，很早就面临和自己类似的问题:大量的数据(信息索引和网页快照等等)要怎么存储存储在哪里的问题。Google选择的是用大量的通用硬件组成一个可以横向扩展的集群去对存储和处理这些海量的数据。这种英雄所见略同的感觉，让小陈决定要从事大数据开发，毕竟这个越来越自我的世界，随着移动互联网的爆发，每个人制造的垃圾数据会越来越容易，而制造垃圾数据的人也会越来越多。&lt;/p&gt;

&lt;h2 id=&#34;第一份工作&#34;&gt;第一份工作&lt;/h2&gt;

&lt;p&gt;找大数据的工作并不顺利，心仪的公司嫌自己没有经验，给Offer的公司貌似没有多少数据，只是想趁着大数据热忽悠一把。阴错阳差，小陈找到一份Java开发的工作。这家公司专做某行业的软件，公司不大但发展很快，待遇还算不错。小陈第一周上班主要学习公司的技术框架，然后就懵逼了。面试时候非要分清POBOVO，现在项目所有的参数传递都是List&lt;Map&gt;；面试时候各种设计模式的问，结果这项目的大部分的业务逻辑都是写在SQL存储过程里面的，甚至JS里面也夹杂了很多SQL；自研的一个工作流框架对应的库表，各种预留字段，从field1，field2一直到field8。在小陈犹豫着要不要换家公司，技术总监的几句话给忽悠住了他：这个世界的所有事物，即所谓的对象，都是可以用List&lt;Map&gt;来表示；SQL是史上的最好的DSL，一定要充分利用，如果想写，用SQL实现一个Dijkstra算法都可以[注1]；这框架虽然不走寻常路，但是有PHP的开发速度，也利用JVM的性能和Java的生态系统。&lt;/p&gt;

&lt;p&gt;小陈不仅觉得总监的话很有道理，而且这些话跟大数据的思路也有几份相似。Google开启大数据时代最重要的就是三篇论文:Google File System,讲如何分布式存储大数据；Google MapReduce,讲如何分布式计算大数据；Google Bigtable,实现了一个数据库，以便在分布式下快速读写结构化数据。对应的开源实现是Hadoop Hdfs，Hadoop MapReduce，HBase。这个识万物为List&lt;Map&gt;的思路不就是MapReduce的思路吗，而那个预留字段的数据库设计其实有点Bigtable/HBase的风范，不管神似与否至少形似。工作一段时间，小陈感觉这糙快猛的框架确实还是很适合这个需求变化比较快的行业，对他自己来说，至少写SQL和实现业务需求的能力提高了不少。一年之后，小陈跳槽到一家三线互联网公司做大数据，凭借的就是这两项能力。&lt;/p&gt;

&lt;h2 id=&#34;大数据工作和两个领导&#34;&gt;大数据工作和两个领导&lt;/h2&gt;

&lt;p&gt;新公司工作主要基于Shell调用Hive，把数据从日志往Oracle里面导，经常还要给业务部门提数。所以，虽然在做大数据，工作内容只是从上家公司的Oracle PL/SQL换成了Hive SQL。Map-Reduce虽然直指大数据计算的本源，但是奈何这个世界太复杂，产品经理的需求太多，表达力有点欠缺。而且又很多通用的需求，例如数据之间的Join和Group，完全可以提炼出来，于是Facebook向开源社区捐献了Hive，用史上的最好的DSL作为查询语言交给熟悉SQL的人去使用，Hive引擎负责把SQL翻译成MapReduce。小陈得偿所愿进入大数据行业，但是很快就厌倦了：Shell管理起来太麻烦，跟其他系统交互起来不方便；Hive运行太慢，资源利用率低，有时候跑了十几分钟结果出来了发现自己的SQL有一个简单的错误；想推动HadoopV2的落地，让Yarn去合理的管理集群资源，领导和同事都不愿意承担风险。小陈隐约觉得自己做的东西并没有给公司带来应有的价值，只是让报表的维度增加一些。领导告诉小陈，大数据并不是解决一切问题的灵丹妙药，数据越来越多，增加更多的是无价值的数据，而大数据处理的日志等数据与业务数据相比，信息熵要低的多。&lt;/p&gt;

&lt;p&gt;就这么工作一年后，老板也对数据部门不满意，赶走了老领导，挖来一个大厂的架构师来主管整合所有数据相关业务。新领导上来就大刀阔斧，部门架构调整，把一部分数据相关的开发并了过来，整个部门一分为二，一部分往上跟业务和产品部门打交道，一部分下沉做大数据平台时候。小陈果断的选择了去做平台。&lt;/p&gt;

&lt;p&gt;如果说老领导强调的是数据完整性和正确性，数据对业务的支撑，新领导更强调数据对产品和决策的反馈，技术的先进性。按照新领导的意思，以做用户数据仓库为出发点，从数据收集、数据转换、数据模型、数据查询、数据可视化到任务调度和平台监控，要重新梳理现有每一个模块的技术架构。这个时候，大数据相关技术已经可以说是百花齐放百家争鸣，围绕着Hadoop，几乎每个领域都有一两个出色的解决方案。领导要求使用技术要向代表技术先进性，相关软件版本落后不能超过2年，鼓励使用3年以内的新项目。小陈很高兴，感觉可以大干一场了。因为态度积极，小陈很受新领导的器重，小陈先负责用其他SQL on Hadoop的如Impala/Presto来代替Hive的部分功能，提高查询效率，后来又负责引入实时计算框架Storm，虽然只是用来计算PV/UV，但好歹是实时的。总之是趟坑无数，背锅无数，忙得不亦乐乎。&lt;/p&gt;

&lt;p&gt;直到又过一年公司裁员，小陈才发现数据部门是重灾区。和领导吃散伙饭，小陈开始鸣不平，觉得咱们的平台做了这么多，大家加班这么辛苦，为什么就没人懂欣赏呢。领导却直言自己早就知道这个结局，部门折腾了一年，老板只看到数据部门人员和机器一直在增加，却经常收到其他部门各种抱怨，产品抱怨进度太慢啊，商务说数据不懂业务啊，研发说总是要配合数据做这做那啊，运营说报表没有老系统方便数据老出问题等等。相处这么久，领导已经把小陈当心腹了，直言一开始想把有些业务拿到数据这边统一处理，技术出身搞不定公司复杂的关系，阻力太大；埋头把平台理顺，而在强势老板的公司里面，自己还是没有抓住老板的需求和业务的痛点，所以对老板来说，确实没为公司带来什么价值。领导的这番肺腑之言对小陈触动很大，开始重新审视自己的过去的工作。不管怎样小陈这时候找下一份工作已经有了一份资本。&lt;/p&gt;

&lt;h2 id=&#34;在创业公司&#34;&gt;在创业公司&lt;/h2&gt;

&lt;p&gt;在全民创业的浪潮中，小陈来到一家创业公司，这里还没有什么&amp;rdquo;大数据&amp;rdquo;,但是CEO的数据要介入整个产品和运营中的承诺和希望打动了小陈，而且这里有机会从零开始有机会按照自己的思路规划整个公司的大数据业务。这个时候，大数据圈最火的是Spark，Spark以基于内存的DAG计算引擎为基础，提供了批量计算，实时计算，交互式查询，机器学习，基本上实现了One Stack To Rule Them All，而且Spark也有SparkSQL。小陈选择了围绕Spark来构建整个系统，并且拥抱云计算了，直接选择云服务，希望自己能专注于让数据产生价值。小陈工作分这么几部分:输出报表数据;给一个数据科学家打杂，帮他整理数据提取特征，实现一些算法;每天花一个小时看数据，解释数据和用数据去解释。小陈成了对公司业务和系统最了解的人，比产品和QA都要了解，并且提出了很多优化和改进。CEO很满意，年终时候大笔一挥给了更多的期权，然而没什么卵用，因为融资寒冬来的时候，公司还是倒了。&lt;/p&gt;

&lt;h2 id=&#34;在大厂&#34;&gt;在大厂&lt;/h2&gt;

&lt;p&gt;小陈已经拖家带口了，感觉自己不再年轻，在机构Offer之间犹豫了很久之后，选择了去一个大厂做螺丝钉，这里流程和工具都已经非常完善了，用的Hadoop都是自己定制甚至已经跟社区不兼容了。小陈业务时间乐于参加各种线下各种活动，积攒自己的人脉，坚持更新Blog，提升自己的名气。&lt;/p&gt;

&lt;p&gt;这个时候Google推出了Beam计算框架。其实Google抛出了三大论文之后，表面上很沉寂，自己内部的系统却一直在向前演进，例如老版的GFS已经被Colossus被代替。直到Google眼红AWS投身云计算时候，发现客户都更习惯开源的那套东西，甚至Google把自己的BigTable服务往外卖的时候，不得不兼容BigTable的山寨产品HBase的API。这就好比一个欧洲人找到一个中国建筑师建一个亚洲古代建筑，中国建筑师给建了一个唐朝风格的建筑，欧洲人说，你这建的不大对，我在日本看到的都是这样那样。Google为了争夺话语权，把自己最新的产品拿出来开源，要一统所有的计算框架，不管你底层是Storm还是Spark，按照Beam的API来处理数据，底层可以随意切换Spark和自家的Cloud Dataflow，甚至为了师出有因，大力提携Flink和Spark打擂台。小陈相信这个框架会一统江湖，为了自己的KPI和升级, 准备在公司推Apache Beam。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Imply和Confluent破解</title>
      <link>https://lawulu.github.io/post/Imply%E5%92%8CConfluent%E7%A0%B4%E8%A7%A3/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Imply%E5%92%8CConfluent%E7%A0%B4%E8%A7%A3/</guid>
      <description>

&lt;p&gt;其实这两个软件还是比较容易破解的，首先开发者并没有把精力放到反破解上面，相关功能做的很简单。第二没有服务器交互的反破解还是很难的，即时是有服务器交互(例如Idea)，也有人搞出各种License Server出来&lt;/p&gt;

&lt;h2 id=&#34;imply-pivot&#34;&gt;Imply Pivot&lt;/h2&gt;

&lt;p&gt;搜索&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;grep -ri &#39;Pivot evaluation license expired&#39; .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;发现有个文件&lt;code&gt;./node_modules/@implydata/im-auth/build/server/utils/license-manager/license-manager.js&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;里面有这个逻辑：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        var e = path.join(this.varDir, &amp;quot;.pivot-first-run&amp;quot;);
        return Q(fs.readFile(e, {encoding: &amp;quot;utf-8&amp;quot;})).then(function (e) {
            var r = new Date(e.trim());
            if (isNaN(r)) throw new Error(&amp;quot;invalid date&amp;quot;);
            return {created: false, firstRun: r}
        }).catch(function (r) {
            var t = new Date;
            return Q(fs.writeFile(e, t.toISOString())).then(function () {
                return {created: true, firstRun: t}
            })
        })
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;找到文件&lt;code&gt;find . -name &amp;quot;.imply-first-run&amp;quot;&lt;/code&gt;
把里面日期改一下就行了&lt;/p&gt;

&lt;h2 id=&#34;confluent&#34;&gt;Confluent&lt;/h2&gt;

&lt;p&gt;坑一：一开始搞反了..一直没报错 还以为没生效&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;jar uf /service/app/confluent-4.0.0/share/java/confluent-control-center/control-center-4.0.0.jar io/confluent/controlcenter/license/LicenseModule.class
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;坑二：zsh ll不显示隐藏文件，习惯把ll = ls-al 而不是ls -ah&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; return License.baseClaims(&amp;quot;demo&amp;quot;, bfa.creationTime().toMillis() + TimeUnit.DAYS.toMillis(30L), true);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;所以其实修改该文件的createTime就行了..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CDN流量日志简单分析</title>
      <link>https://lawulu.github.io/post/CDN%E6%B5%81%E9%87%8F%E6%97%A5%E5%BF%97%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/CDN%E6%B5%81%E9%87%8F%E6%97%A5%E5%BF%97%E7%AE%80%E5%8D%95%E5%88%86%E6%9E%90/</guid>
      <description>

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;公司运营的很大一个成本就是CDN耗费。对比Impression和CDN消耗量就会很奇怪，不该有这么多的CDN消耗的。&lt;/p&gt;

&lt;h2 id=&#34;数据分析&#34;&gt;数据分析&lt;/h2&gt;

&lt;h3 id=&#34;下载并处理cdn原始日志&#34;&gt;下载并处理CDN原始日志&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;由于官方提供的合并下载日志工具在Mac下不能用，随机选取一个小时的日志：&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;wget https://cdnlog.cn-hangzhou.oss.aliyun-inc.com/streaming.lawulu.com/2017_03_04/streaming.lawulu.com_2017_03_04_1200_1300.gz?spm=5176.8232200.log.d10.83JI60&amp;amp;OSSAccessKeyId=xxxxx&amp;amp;
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;Python处理分析为CSV&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;pat = ( r&#39;\[(.+)\]\s&#39; #datetime
           &#39;(\d+.\d+.\d+.\d+)\s&#39; #IP address
           &#39;-\s&#39; #proxy ip
            &#39;\d+\s&#39; #responseTime
           &#39;&amp;quot;.+&amp;quot;\s&#39; #referrer
           &#39;&amp;quot;(GET\s\S+mp4)&amp;quot;\s&#39;  # requested file
            &#39;\d+\s&#39; #status
           &#39;\d+\s&#39; #requestSIze
           &#39;(\d+)\s&#39; #responseSize
           &#39;\D+\s&#39; #HIT OR NOT
           &#39;&amp;quot;(.+)&amp;quot;\s&#39; #user agent
           &#39;&amp;quot;\S+&amp;quot;&#39; #contentType
        )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;@see &lt;a href=&#34;https://github.com/richardasaurus/nginx-access-log-parser/blob/master/main.py&#34;&gt;https://github.com/richardasaurus/nginx-access-log-parser/blob/master/main.py&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;导入数据库&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;LOAD DATA INFILE &#39;cdnlogs.csv&#39; 
INTO TABLE test.cdn_log
FIELDS TERMINATED BY &#39;,&#39; 
LINES TERMINATED BY &#39;\n&#39; 
(date_time,ip,url,rsp_size,ua);
&lt;/code&gt;&lt;/pre&gt;

&lt;ol&gt;
&lt;li&gt;数据校验&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*)  FROM test.cdn_log 
&#39;206619&#39;

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cat streaming.lawulu.com_2017_03_04_1200_1300 | wc -l

206618
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;用sql分析&#34;&gt;用Sql分析&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;
select count(*), sum(rsp_size) from (

SELECT ip,ua,url,sum(rsp_size) as rsp_size FROM test.cdn_log group by ip,ua,url having count(*) =1 )a


&#39;110643&#39;,&#39;598635187514&#39;


select count(*), sum(rsp_size) from (

SELECT ip,ua,url,sum(rsp_size) as rsp_size FROM test.cdn_log group by ip,ua,url having count(*) &amp;gt;1 )a


&#39;32670&#39;, &#39;440010318426&#39;

0.4236
select 440010318426/(598635187514+440010318426) from dual 

select sum(rsp_size) from  cdn_log

1038645505940

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;

&lt;p&gt;由于IP,UA,URL可以唯一确定一次UV，我们公司有30%的用户占用了40%的流量，对同一个视频会不停的反复下载。
最后查明，是SDK的bug，正在下载视频时候，如果切换到后台，下载会直接停止。所以会反复下载视频，浪费流量。&lt;/p&gt;

&lt;h2 id=&#34;校验&#34;&gt;校验&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;计算ResponseSize之后和Console里面同一时间段的&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;
CURL  -i -X HEAD &#39;https://streaming.lawulu.com/default/256b9db1-a1ce-4983-8906-4568fa7a9c75-144.mp4&#39;
&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>广协的IP库到底准不住</title>
      <link>https://lawulu.github.io/post/%E5%B9%BF%E5%8D%8F%E7%9A%84IP%E5%BA%93%E5%88%B0%E5%BA%95%E5%87%86%E4%B8%8D%E4%BD%8F/</link>
      <pubDate>Sat, 25 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E5%B9%BF%E5%8D%8F%E7%9A%84IP%E5%BA%93%E5%88%B0%E5%BA%95%E5%87%86%E4%B8%8D%E4%BD%8F/</guid>
      <description>

&lt;h2 id=&#34;缘起&#34;&gt;缘起&lt;/h2&gt;

&lt;p&gt;对于CPM广告，地域定向是非常重要的。广告协会提供了ip库，方便AdNetwork和第三方监控做地域定向。百度默认以ip138做为其&amp;rdquo;IP&amp;rdquo;关键字的第一个入口，我相信ip138的库是比较准的，那广协的IP库和ip138的库差别大吗？&lt;/p&gt;

&lt;h2 id=&#34;数据分析&#34;&gt;数据分析&lt;/h2&gt;

&lt;h3 id=&#34;随机从线上提取10000个ip-并使用广协库解析成对应城市&#34;&gt;随机从线上提取10000个ip，并使用广协库解析成对应城市&lt;/h3&gt;

&lt;p&gt;从某个时段原始Nginx日志中的ip(300W+)随机取10000条
使用pandas&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;csv = pd.read_csv(&#39;/tmp/ip.log&#39;)
np.savetxt(&#39;/tmp/ipSample.log&#39;,csv.sample(10000).values,fmt=&#39;%s&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;根据ip获取ip138对应的城市&#34;&gt;根据ip获取ip138对应的城市&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;reload(sys)
sys.setdefaultencoding(&#39;utf-8&#39;)

# get data from web
def get_data(query):
    url = &amp;quot;http://m.ip138.com/ip.asp?ip=&amp;quot; + query
    res = requests.get(url)
    print &#39;get data for &#39;+ query +&#39; result:&#39; + str(res.status_code)
    if(res.status_code != 200):
        return &#39;Failed Response&#39;
    else:
        return parse_html(res.content)

def parse_html(html):
    res = BeautifulSoup(html,&amp;quot;html.parser&amp;quot;).find_all(&amp;quot;p&amp;quot;, &amp;quot;result&amp;quot;)
    result =split(res[0])
    if len(res)&amp;gt;1:
        result=result+&amp;quot;,&amp;quot;+ split(res[1])
    return result

def split(str):
    try:
        splits=str.string.encode(&amp;quot;utf-8&amp;quot;).split(&#39;：&#39;)
        return splits[1]
    except RuntimeError:
        return &#39;Split Error:&#39;+str

with open(&#39;/tmp/ipSample.log&#39;) as source:
    with open(&#39;ip138Result.csv&#39;,&#39;aw&#39;) as result:
        for line in source:
            ip = line.strip(&#39;\n&#39;)
            ipStr=get_data(ip)
            time.sleep(0.1)
            result.write(ip+&#39;|&#39;+ipStr+&#39;\n&#39;)

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;取全国60强城市-统计两个结果的差距&#34;&gt;取全国60强城市，统计两个结果的差距&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.mnw.cn/news/china/886245.html&#34;&gt;http://www.mnw.cn/news/china/886245.html&lt;/a&gt; 60强城市&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;citys=[&#39;上海&#39;,&#39;北京&#39;,&#39;广州&#39;,&#39;深圳&#39;,&#39;成都&#39;,&#39;重庆&#39;,&#39;杭州&#39;,&#39;南京&#39;,&#39;沈阳&#39;,&#39;苏州&#39;,&#39;天津&#39;,&#39;武汉&#39;,&#39;西安&#39;,&#39;长沙&#39;,&#39;大连&#39;,&#39;济南&#39;,&#39;宁波&#39;,&#39;青岛&#39;,&#39;无锡&#39;,&#39;厦门&#39;,&#39;郑州&#39;,&#39;长春&#39;,&#39;常州&#39;,&#39;哈尔滨&#39;,&#39;福州&#39;,&#39;昆明&#39;,&#39;合肥&#39;,&#39;东莞&#39;,&#39;石家庄&#39;,&#39;呼和浩特&#39;,&#39;南昌&#39;,&#39;温州&#39;,&#39;佛山&#39;,&#39;贵阳&#39;,&#39;南宁&#39;,&#39;海口&#39;,&#39;湖州&#39;,&#39;唐山&#39;,&#39;临沂&#39;,&#39;嘉兴&#39;,&#39;绍兴&#39;,&#39;南通&#39;,&#39;徐州&#39;,&#39;泉州&#39;,&#39;太原&#39;,&#39;烟台&#39;,&#39;乌鲁木齐&#39;,&#39;潍坊&#39;,&#39;珠海&#39;,&#39;洛阳&#39;,&#39;中山&#39;,&#39;兰州&#39;,&#39;金华&#39;,&#39;淮安&#39;,&#39;吉林&#39;,&#39;威海&#39;,&#39;淄博&#39;,&#39;银川&#39;,&#39;扬州&#39;,&#39;芜湖&#39;,&#39;盐城&#39;,&#39;宜昌&#39;,&#39;西宁&#39;,&#39;襄阳&#39;,&#39;绵阳&#39;]
files =[&amp;quot;ip138Result.csv&amp;quot;,&amp;quot;ipResultV2.log&amp;quot;]
import subprocess, datetime, sys
def checkNums(file,city):
    p = subprocess.Popen(&amp;quot;&amp;quot;&amp;quot; cat &amp;quot;&amp;quot;&amp;quot; + file + &amp;quot;&amp;quot;&amp;quot;| grep &amp;quot;&amp;quot;&amp;quot;+ city +&amp;quot;&amp;quot;&amp;quot;  |wc -l &amp;quot;&amp;quot;&amp;quot;, shell=True, stdout=subprocess.PIPE );
    p.wait()
    out = p.stdout.readlines()[0]
    return str(out).strip()

for city in citys:
    result = city + &amp;quot;\t&amp;quot;
    for file in files:
        result = result +checkNums(file,city)+ &amp;quot;\t&amp;quot;
    print  result
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;北京相差比较大，系统库比Ip138库多出一倍&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;其他城市 上海 深圳 南京 苏州 大连 宁波等也相差在20%以上。
可以说跟IP138差别还是比较大的。&lt;/p&gt;

&lt;p&gt;但是三线城市比较准。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>AngularJS初窥</title>
      <link>https://lawulu.github.io/post/AngularJS%E5%88%9D%E7%AA%A5/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/AngularJS%E5%88%9D%E7%AA%A5/</guid>
      <description>

&lt;p&gt;无数人吐槽过前端框架的层出不穷,眼看前端开发要脱离浏览器兼容性的苦海,又要落入框架碎片的深坑.从语言本身到编译到打包到开发框架各种框架层出不穷&amp;hellip;是终端用户需求太多还是前端大牛们野心太大? 不管怎样,报G家大腿选择Angular似乎没什么问题,另一个大腿的Reactive本身不是一个完备的框架.&lt;/p&gt;

&lt;h2 id=&#34;angular简介&#34;&gt;Angular简介&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在Web开发中需要JS做什么？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;与服务器交互&lt;/li&gt;
&lt;li&gt;操作DOM&lt;/li&gt;
&lt;li&gt;简单的逻辑控制&lt;/li&gt;
&lt;li&gt;输入验证&lt;/li&gt;
&lt;li&gt;路由&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Angular做了什么改变？&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;引入了指令,ng开头,来扩展HTML&lt;/li&gt;
&lt;li&gt;数据绑定,通过对HTML元素增加指令ng-model&lt;/li&gt;
&lt;li&gt;使用directive来自定义指令&lt;/li&gt;
&lt;li&gt;Scope,提供了HTML视图和JS控制器之间的纽带&lt;/li&gt;
&lt;li&gt;Controller,可以视为一个$Scope的构造函数&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;数据绑定 即将Dom的变化绑定到数据的变化上面去,因为用的1,所以这个绑定是双向的,有时候想只改变页面,会影响到数据&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;使用一周的感受&#34;&gt;使用一周的感受&lt;/h2&gt;

&lt;h3 id=&#34;一些坑&#34;&gt;一些坑:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;架构很恢弘，学习曲线很陡峭&lt;/li&gt;
&lt;li&gt;http是异步,要在.function中处理,为避免因为异步未完成引起的页面问题，课可以统一在配置里面设置&lt;code&gt;async : true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;怎么Lazy初始化？没有找到办法，可能需要自定义Directive&lt;/li&gt;
&lt;li&gt;一些自定义Directive封装的不彻底，各种问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;controller之间的交互&#34;&gt;Controller之间的交互&lt;/h3&gt;

&lt;p&gt;两种办法&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://stackoverflow.com/questions/29467339/how-to-call-a-function-from-another-controller-in-angularjs&#34;&gt;http://stackoverflow.com/questions/29467339/how-to-call-a-function-from-another-controller-in-angularjs&lt;/a&gt;
本质是绑定到RootScope里面,通过事件来响应&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.csdn.net/findsafety/article/details/50403242&#34;&gt;http://blog.csdn.net/findsafety/article/details/50403242&lt;/a&gt;
原生dom与js的处理办法,可能会版本之间不兼容,本质是通过dom找到Ng-controller的方法.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;    var appElement = document.querySelector(&#39;[ng-controller=&amp;quot;EndCardEditCtrl as ctrl&amp;quot;]&#39;);
    var editCtrl = angular.element(appElement);
    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;与jquery-js之间的交互&#34;&gt;与Jquery/JS之间的交互&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;有时候Jquery绑定Function时候,Dom并没有生成,所以需要替换成Angular的&lt;code&gt;ng-click&lt;/code&gt;事件,或者需要绑定到顶级上面,冒泡绑定.&lt;/li&gt;
&lt;li&gt;JS中可以通过元素来找的其绑定的scope
&lt;code&gt;
window.angular.element(&amp;quot;#divId&amp;quot;).scope().doSth()
&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;angular的分支循环&#34;&gt;Angular的分支循环&lt;/h3&gt;

&lt;p&gt;Angular提供了Ng-show等逻辑判断,来控制页面的变化.
提供了Switch和For来做分支和循环.
简单来说,基本可以对Html的显示进行编程.&lt;/p&gt;

&lt;h3 id=&#34;scope-apply&#34;&gt;$scope.$apply()&lt;/h3&gt;

&lt;p&gt;点击按钮之后,为什么会绑定成功?奥秘就在于Angular把&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Events =&amp;gt; ng-click
Timeouts =&amp;gt; $timeout
jQuery.ajax() =&amp;gt; $http
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;都Wrapper了,只要这些事件被触发,自动调用&lt;code&gt;$scope.$apply()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;问题是很多时候(在$scope之外的操作)需要自己手动调用, 但是Angular又保证此方法不能调用两次.
所以官方推荐使用Angular自己那套($Resource,$Route,service之类&amp;hellip;).恩,有种上了贼船的感觉.&lt;/p&gt;

&lt;h3 id=&#34;resource&#34;&gt;$Resource&lt;/h3&gt;

&lt;p&gt;一个对HttpRest的封装,简单的CRUD确实很方便,但是遇到复杂的需求就要抓瞎,很多时候需要调整后端..所以有很多人说,Angular适合做简单的CRUD应用.&lt;/p&gt;

&lt;h3 id=&#34;ng-change&#34;&gt;Ng-change&lt;/h3&gt;

&lt;p&gt;ng-change requires ng-model, without it will not work&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error: [$compile:ctreq] http://errors.angularjs.org/1.4.5/$compile/ctreq?p0=ngModel&amp;amp;p1=ngChange

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;另外 ng-change对File不生效&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/angular/angular.js/issues/1375&#34;&gt;https://github.com/angular/angular.js/issues/1375&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;单元测试&#34;&gt;单元测试&lt;/h3&gt;

&lt;p&gt;Angular轮了一套Service,Factory之流,自然也少不了单元测试..不知道有多少人会为页面写这玩意.&lt;/p&gt;

&lt;h2 id=&#34;angular自定义directive和ng-repeat的问题&#34;&gt;Angular自定义Directive和Ng-repeat的问题&lt;/h2&gt;

&lt;h3 id=&#34;现象&#34;&gt;现象&lt;/h3&gt;

&lt;p&gt;同事自定义了一个&lt;code&gt;directive&lt;/code&gt;，模仿&lt;a href=&#34;http://www.cnblogs.com/e50000/p/5663806.html&#34;&gt;这里&lt;/a&gt;做的一个日期控件。这个&lt;code&gt;directive&lt;/code&gt;需要input域里面含有一个id。另外一个同事想在 &lt;code&gt;np-repeat&lt;/code&gt;里面使用这个控件，为了保证id唯一性，写成了这样，&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; &amp;lt;input type=&amp;quot;text&amp;quot; ng-model=&amp;quot;statDatas[$index].endDate&amp;quot; class=&amp;quot;overviews_date&amp;quot; placeholder=&amp;quot;结束时间&amp;quot; &amp;quot;id=&amp;quot;{{&#39;startDateInput&#39;+$index}}&amp;quot;  ng-change=&amp;quot;statDateChanged($index)&amp;quot; readonly  def-laydate&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果一直报错&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TypeError: Cannot read property &#39;tagName&#39; of undefined
    at Object.Dates.run (http://localhost:8081/resources/js/laydate.js:171:42)
    at win.laydate (http://localhost:8081/resources/js/laydate.js:34:11)
    at link (http://localhost:8081/resources/platformJs/ad_angular.js:592:20)
    at http://localhost:8081/resources/angular/angular.min.js:72:493
    at $ (http://localhost:8081/resources/angular/angular.min.js:73:46)
    at L (http://localhost:8081/resources/angular/angular.min.js:61:495)
    at g (http://localhost:8081/resources/angular/angular.min.js:54:326)
    at g (http://localhost:8081/resources/angular/angular.min.js:54:349)
    at g (http://localhost:8081/resources/angular/angular.min.js:54:349)
    at g (http://localhost:8081/resources/angular/angular.min.js:54:349) &amp;lt;input type=&amp;quot;text&amp;quot; ng-model=&amp;quot;statDatas[$index].startDate&amp;quot; class=&amp;quot;overviews_date ng-pristine ng-untouched ng-valid ng-isolate-scope&amp;quot; placeholder=&amp;quot;开始时间&amp;quot; id=&amp;quot;{{&#39;startDateInput&#39;+$index}}&amp;quot; ng-change=&amp;quot;statDateChanged($index,ad.id)&amp;quot; readonly=&amp;quot;&amp;quot; def-laydate=&amp;quot;&amp;quot;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;分析&#34;&gt;分析&lt;/h3&gt;

&lt;p&gt;一开始就怀疑，是因为执行这个&lt;code&gt;directive&lt;/code&gt;时候&lt;code&gt;np-repeat&lt;/code&gt;还没有执行完，即这个dom还没有渲染完毕。那怎么解决呢？
1. 监听&lt;code&gt;np-repeat&lt;/code&gt;,等结束之后，再去动态的执行自定义&lt;code&gt;directive&lt;/code&gt;。例如这篇文章里面：&lt;a href=&#34;http://www.tuicool.com/articles/Fb2um2e&#34;&gt;利用angular指令监听ng-repeat渲染完成后执行脚本&lt;/a&gt;
2. 貌似有个Priority的属性，然而，搜了一下&lt;code&gt;np-repeat&lt;/code&gt;的Priority非常大，为1000，而自定义的priority为0.
3. 仔细看报错日志，感觉像是laydate里面拿到的document是angular渲染之前的，所以找不到对应的Input域。这时候搜索已经没有意义了，应该仔细弄清楚&lt;code&gt;directive&lt;/code&gt;各行代码的意义。
4. scope的问题？&lt;/p&gt;

&lt;h3 id=&#34;解决办法&#34;&gt;解决办法&lt;/h3&gt;

&lt;p&gt;用原始的值传递和&lt;code&gt;$scope.$apply&lt;/code&gt;来交互数据，弃掉自定义控件&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Phantomjs和Casperjs初窥</title>
      <link>https://lawulu.github.io/post/Phantomjs%E5%92%8CCasperjs%E5%88%9D%E7%AA%A5/</link>
      <pubDate>Sun, 23 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Phantomjs%E5%92%8CCasperjs%E5%88%9D%E7%AA%A5/</guid>
      <description>

&lt;p&gt;在这个浏览器最大的时代，JS越来越重的时代，做爬虫其实最好的办法是找一个Headless浏览器，必须要支持执行JS，这样做爬虫就不用去分析HTTP和JS了。我大Java有HtmlUnit，最近尝试的是传说中的PhantomJs。话说为什么没有基于Chrome dev tools的爬虫框架呢，或许可以尝试下油猴子。&lt;/p&gt;

&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;PhantomJs提供了最原始的API，Casperjs是对PhantomJs的包装，最方便的是不用不停的写if/else（成功了执行下一步），而是用then/wait等方法增加代码的可读性和可写性。不过，Casperjs官方文档直接给出，遇到问题，应该使用PhantomJs的方式先去调用，有问题也要去PhantomJs那里去提…所以，看文档还是直接上PhantomJs吧。&lt;/p&gt;

&lt;h2 id=&#34;示例&#34;&gt;示例&lt;/h2&gt;

&lt;p&gt;casperjs提供了&lt;code&gt;echo&lt;/code&gt;、&lt;code&gt;waitfor&lt;/code&gt;、&lt;code&gt;click&lt;/code&gt;等原语，所以代码大概是这样：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;casper.thenClick(&#39;li.pg_next&#39;);

casper.then(function () {
    this.waitForSelector(&#39;li.pg_next&#39;,function () {
         this.echo(this.getHTML(&#39;.post-list&#39;));
    });
})
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;比较苦逼的是，只有通过文件和console来跟外界交互…casperjs提供了一个server示例，直接标注说有内存溢出风险，phantomjs直接把webserver标注为不可在生产上用。&lt;/p&gt;

&lt;h2 id=&#34;debug&#34;&gt;Debug&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;casperjs --ignore-ssl-errors=yes --ssl-protocol=any  sample.js  --remote-debugger-port=9000 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这时候，可以在Safari里面打开，在Scripts里面设置断点，就可以Debug了。看似简单，但是很多坑在里面。&lt;/p&gt;

&lt;p&gt;首先，要在console里面执行__run()，但是如果&lt;code&gt;sample.js&lt;/code&gt;如果太复杂的话，会直接把PhantomJs搞Crash。所以可以在代码里面加上&lt;code&gt;Debugger&lt;/code&gt;，这样直接能跳过Crash的地方。
另外，PhantomJs是基于Webkit的，Chrome虽然有Webkit血统，但是只使用了起渲染HTML和CSS这一层，自己搞了一套V8去执行JS，所以，最新版本的Chrome是无法Debug PhantomJs的，最好使用血缘更近的Safari。另外再吐槽一下，PhantomJs的Bug真多，动不动就Crash。&lt;/p&gt;

&lt;p&gt;而且Console实在是不方便，所以，我觉得，最好的Debug还是用capture截图和多用log输出，例如监听资源。&lt;/p&gt;

&lt;h2 id=&#34;监听资源&#34;&gt;监听资源&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt; var utils = require(&#39;utils&#39;);

casper.options.onResourceReceived = function(casperObject, res) {
     var contentType = res.contentType;
     if(contentType.indexOf(&amp;quot;json&amp;quot;)!=-1){
        console.log(utils.dump(res));

     }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这里可以打印出所有header为&lt;code&gt;application/json&lt;/code&gt;的请求，然而没什么卵用，因为一般来说，body都被Gzip了，这里比较适合的是打印出url。&lt;/p&gt;

&lt;p&gt;另外一个坑是，PhantomJs退出时候，可能有很多Ajax请求还没有完成，所以这里要手动Wait……,不然很多请求抓不到，再所以，PhantomJs抓起来就比较慢，适合一些临时的小任务。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>闲言碎语·老人与孩</title>
      <link>https://lawulu.github.io/post/%E8%80%81%E4%BA%BA%E4%B8%8E%E5%AD%A9/</link>
      <pubDate>Fri, 07 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E8%80%81%E4%BA%BA%E4%B8%8E%E5%AD%A9/</guid>
      <description>&lt;p&gt;国庆前打车从西站回家，路遇一个炒房大叔司机，一路叨叨他们去河北买房的事情，中间有句话印象很深，是说和儿子商量怎么理财的事情：老人有老人的经验，年轻人有年轻人的闯劲。&lt;/p&gt;

&lt;p&gt;我对本地人最羡慕的一点就是，一直生活在生活的传承之下。不仅是生活的一些小窍门，还有很多为人处世的言传身教。&lt;/p&gt;

&lt;p&gt;这么多年没有和父母在一起生活，不管是生活理念还是人生观，因为缺少磨合和沟通，差距很大，如果按照一直以来连岳的说法，不要试图去改变他们。之前去郑州，父亲一直说我们办事情考虑问题不全面，没有把生孩子这件事给重视起来，万一某个环节出了问题，要后悔终生的。&lt;/p&gt;

&lt;p&gt;我想起了另一件事，儿子刚出生时候，因为住院，睡成了偏头，一个耳朵有点招风，然后又折腾母乳过敏，所以招风耳这事，一直没有太重视。岳母曾经说过几次说要用胶布粘住，妻子觉得会把皮肤粘疼，也向我转述过这种想法，我下意识的把这事当成了笑话来听，说不用，招风耳就当听逆言了。直到上次因为偏头去保健科（去晚了），才听说耳朵长不回来了，只有月子里面粘住耳朵有用，才开始着急，力图让妻子赶紧淘宝买一个。因为这事，差点吵了一架。&lt;/p&gt;

&lt;p&gt;另外，母亲最近在北京看孩子，向我展示了她的耳朵，我才知道她小时候耳朵也被压了，两个耳朵不对称。同样的教训竟然发生在一个家庭两代人身上！之前因为为尊者讳的原因，我从来不知道！幸好，现在头发长了，基本看不出来。&lt;/p&gt;

&lt;p&gt;我相信网络和权威（医院），但是网络和权威并没有给一个完全性的指南。遇上问题再去搜索，肯定要晚了。&lt;/p&gt;

&lt;p&gt;现在父母在这里看孩子，下意识的还是觉得父母的做法有问题，不如网上随便一个论坛里面的只言片语。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>知乎回答·河北高考分数高意味着什么</title>
      <link>https://lawulu.github.io/post/%E6%B2%B3%E5%8C%97%E9%AB%98%E8%80%83%E5%88%86%E6%95%B0%E7%BA%BF/</link>
      <pubDate>Mon, 27 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E6%B2%B3%E5%8C%97%E9%AB%98%E8%80%83%E5%88%86%E6%95%B0%E7%BA%BF/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/31762126/answer/107369501&#34;&gt;https://www.zhihu.com/question/31762126/answer/107369501&lt;/a&gt;
利益相关:十几年前的河南考生&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;河南山西江西的考生的应试能力差不多,河北考生的应试能力完全碾压其他几省. 但这事是河北考生的悲哀而不是骄傲.&lt;/p&gt;

&lt;p&gt;上面很多答案已经说了是衡水中学的影响, 有兴趣的可以研究一下衡水中学跟河北整体分数的相关性.
我上学时候,貌似从来没有听说过河北考生的分数这么高,大概是衡水中学起来之后,河北高考分数越来越变态的.2016年河北700分以上达到了恐怖的168人,比去年多了90+..&lt;/p&gt;

&lt;p&gt;这对高中生来说是好事还是坏事?&lt;/p&gt;

&lt;p&gt;可能是好事,&lt;strong&gt;如果通过高中的训练,能有能力把一件事做的比全国其他同龄人更好,或许以后人生在其他竞争中应该更容易胜出.&lt;/strong&gt;
但是,我觉得肯定大部分家长不愿意自己孩子在高强度压力和竞争之下,需要比全国其他同龄人花费更多的时间和精力去拼命学习,去刷题(天赋一般的话理科考高分基本靠刷题),去练字(可以搜下衡水中学的语文英语作文字体). 而对于没有进入超级中学,或者进入超级中学而高考失败的考生,更是残酷.&lt;/p&gt;

&lt;p&gt;说说我老家的情况,豫南某县城. 县城两所高中,一个重点一个普通,我高考时候重点高中班级前十基本可以进一本线,而现在一个班前三名才有可能进一本线.
跟我们那时候比,一个是生源差了,初中按片升学,没有重点初中,中考招生,教委要求重点高中在某个分数线之后需要和普通高中轮流录取,换句话来说,重点高中不重点了,想想90年代时候,母校每个年级还有重点班,也被教委给取消了;另外就是很多好老师都去大城市了,也招不来好老师了.事实上,跨县高中之间竞争不大,升学率跟校长和县教委政绩挂钩不大,教委和校长没有动力去高压学生.&lt;/p&gt;

&lt;p&gt;高考不公平,单纯讨论分数没有意义. 因为各省市的情况不一样. 假如全国一套卷子一个录取线,相信我,不出三年,帝都人大附学生的考分绝对不比衡水差. 横向比较一本率(考虑到很多省内211招取了很多本地考生,或许用985录取率)才有意义.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>闲言碎语·网络作家的水平如何</title>
      <link>https://lawulu.github.io/post/%E7%BD%91%E7%BB%9C%E4%BD%9C%E5%AE%B6/</link>
      <pubDate>Sat, 16 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E7%BD%91%E7%BB%9C%E4%BD%9C%E5%AE%B6/</guid>
      <description>&lt;p&gt;今天在知乎看到有人在推采铜的新书：《精进：如何成为一个很厉害的人》。去jd和z家，居然都缺货，上次买《机器学习》也是这样，难道现在卖书也靠水军（网上口碑非常好）和饥渴营销（缺货）了吗？&lt;/p&gt;

&lt;p&gt;其实，买过几本网上成名的作家，包括我非常喜欢的马伯庸，实体书都非常烂，在网上抖机灵还可以 系统的写点东西出来就不行了。&lt;/p&gt;

&lt;p&gt;不是说文笔不行，大概是太过失望了。其实现代人看书已经没人在乎文笔了， 小说类都是在拼讲故事的能力和想象力， 非小说类就是能把事情说清楚就行。&lt;/p&gt;

&lt;p&gt;群里面有人批评韩寒的长安乱，说有次韩寒上节目批评冰心文字不好，而&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;冰心还写过一篇东西关于少年儿童写日记的问题，好象是答小读者吧。里面写的关于文章里的毛病，你看韩寒基本上就是这样。比如喜欢用“最”，“极”之类的，但没有具体的描述，因为观察不细致，而词汇也不够 —— 这个就基本上说韩了&lt;/p&gt;

&lt;p&gt;想起之前余秋雨讲他在路边小报看一个案件，一个绑架案，根据案犯的一条纸条判断出案犯语文水平很高抓住案犯的，那纸条写的非常言简意赅条理清楚&lt;/p&gt;

&lt;p&gt;韩寒在模仿钱钟书，钱也是一个很简单的事情，非要绕着说，但是绕的非常耐读非常有意思。这段模仿的太拙劣了&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>招人很难</title>
      <link>https://lawulu.github.io/post/%E6%9C%80%E8%BF%91%E6%8B%9B%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E5%87%A0%E4%B8%AA%E6%83%B3%E6%B3%95/</link>
      <pubDate>Fri, 18 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E6%9C%80%E8%BF%91%E6%8B%9B%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E5%87%A0%E4%B8%AA%E6%83%B3%E6%B3%95/</guid>
      <description>&lt;p&gt;其实要求很简单：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;会Hive,能用Hive完成基本需求。真正的接触过一个线上项目。&lt;/li&gt;
&lt;li&gt;有责任心,靠谱,因为要独当一面,能保证数据的完整性和准确性。&lt;/li&gt;
&lt;li&gt;能以数据的思维来提供业务。&lt;/li&gt;
&lt;li&gt;加分项:日志收集/Spark/机器学习。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;招人很难，
1. 跟着培训班或者看视频学了一些皮毛，或者在数据部门打杂，问起各种原理工具，也答得可以，但是一让解决问题，连思路都没有。
2. 真正做过的要价很高，所以我觉得还不如从Java培养，毕竟我们这有相当一部分工作是用Java做Batch&lt;/p&gt;

&lt;p&gt;我总结的一些发问点：
- Hadoop常用的组件，相关软件，namenode原理，为什么要有Yarn？
- Hadoop相关组件，Zookeeper，Sqoop，Hbase等
- 用过哪些dfs命令？Hadoop常用端口？文件block？如何计算集群所需的硬盘大小？
- Hive Sql原理  &lt;a href=&#34;http://tech.meituan.com/hive-sql-to-mapreduce.html&#34;&gt;http://tech.meituan.com/hive-sql-to-mapreduce.html&lt;/a&gt;
- Hive UDF UDAF区别，Hive 行转列怎么实现？ concat_ws collection
- HiveClient和Beeline区别
- 数据倾斜问题&lt;a href=&#34;http://www.cnblogs.com/ggjucheng/archive/2013/01/03/2842860.html&#34;&gt;http://www.cnblogs.com/ggjucheng/archive/2013/01/03/2842860.html&lt;/a&gt;
- Hive Metadata作用，Hive 分区表，新增一个字段，老的日志不认，显示为空，如何处理？&lt;a href=&#34;http://blog.csdn.net/lxpbs8851/article/details/17118841&#34;&gt;http://blog.csdn.net/lxpbs8851/article/details/17118841&lt;/a&gt;
- Spark的优势？
- 流计算Storm Trident API，如何保证有且只有一次
   &lt;a href=&#34;http://www.flyne.org/article/222&#34;&gt;http://www.flyne.org/article/222&lt;/a&gt;
- 任务调度：
重试，幂等性
如何保证数据的完整性和准确性？
- 点击去重
例如：logtime,userId,adId,actionType, 1小时内的点击只能算一次。
- Hive表存储的方式？哪些常用的文件存储格式？
- simpledateformat的多线程问题 MR中会有问题吗？
- Hive提高Map的数量，Hive小文件CombinedInputFormat
- 可视化，Ad hoc
- 数据仓库相关，如何分层，建模？拉链表&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Redis的安全哲学</title>
      <link>https://lawulu.github.io/post/Redis%E7%9A%84%E5%AE%89%E5%85%A8%E5%93%B2%E5%AD%A6/</link>
      <pubDate>Mon, 15 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Redis%E7%9A%84%E5%AE%89%E5%85%A8%E5%93%B2%E5%AD%A6/</guid>
      <description>

&lt;p&gt;最近看到Redis的作者antirez写的一篇blog: &lt;a href=&#34;http://antirez.com/news/96&#34;&gt;http://antirez.com/news/96&lt;/a&gt;
里面有些东西很有意思.摘录一些观点:&lt;/p&gt;

&lt;h2 id=&#34;为什么redis这么多-安全漏洞&#34;&gt;为什么Redis这么多&amp;rdquo;安全漏洞&amp;rdquo;?&lt;/h2&gt;

&lt;p&gt;作者说经常收到一些Redis不安全的Report,但是大部分Report其实跟Redis没有什么关系或者说对Redis来说无关紧要.因为Redis的绝大多数用户都是将Redis放到一个安全的环境里面,而安全是一个很大的feature,Redis不会为了一小撮用户做开发这么复杂的功能.
&amp;gt;it’s totally insecure to let untrusted clients access the system, please protect it from the outside world yourself&lt;/p&gt;

&lt;h2 id=&#34;一次hack过程&#34;&gt;一次Hack过程&lt;/h2&gt;

&lt;p&gt;安全页面写到: &lt;a href=&#34;http://redis.io/topics/security&#34;&gt;http://redis.io/topics/security&lt;/a&gt;
&amp;gt;the ability to control the server configuration using the CONFIG command makes the client able to change the working directory of the program and the name of the dump file. This allows clients to write RDB Redis files at random paths, that is a security issue that may easily lead to the ability to run untrusted code as the same user as Redis is running&lt;/p&gt;

&lt;p&gt;所以,使用config命令可以往主机的Path写文件,作者展示了这一过程(为防止有些&lt;code&gt;script kiddies cut &amp;amp; paste the attack&lt;/code&gt;,没有直接提供一个脚本,并且还首先备份了当前的数据,这里省略一些无关紧要的步骤):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;生成一对RSA key,并且写到一个文件里面,前后加上换行符
&lt;code&gt;
$ (echo -e &amp;quot;\n\n&amp;quot;; cat id_rsa.pub; echo -e &amp;quot;\n\n&amp;quot;) &amp;gt; foo.txt
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将public key写到一个KV里面
&lt;code&gt;
cat foo.txt | redis-cli -h 192.168.1.11 -x set crackit
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;设置工作目录
&lt;code&gt;
config set dir /Users/antirez/.ssh/
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将内存中数据保存到Db文件中
&lt;code&gt;
config set dbfilename &amp;quot;authorized.keys&amp;quot;
save
&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;大功告成!&lt;/p&gt;

&lt;h2 id=&#34;为什么不默认bind-127-0-0-1&#34;&gt;为什么不默认bind 127.0.0.1?&lt;/h2&gt;

&lt;p&gt;事实上,如果启动时候带上默认的配置文件(redis.conf),就不存在这个安全隐患,因为配置文件里面默认是只绑定了Loopback address.既然作者知道这个安全隐患,为什么不默认启用这个配置文件呢?(就像Mysql那样).&lt;/p&gt;

&lt;p&gt;作者的解释是,因为RTFM（Read The Fucking Manual）&lt;/p&gt;

&lt;h2 id=&#34;使用auth&#34;&gt;使用Auth&lt;/h2&gt;

&lt;p&gt;虽然并不能真正解决安全问题..最简单有效的方法就是使用Auth.使用Auth的的几点说明:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;密码要尽可能的复杂,以防被brute force&lt;/li&gt;
&lt;li&gt;Auth的消耗非常少,只是在连接建立时候做一次鉴权,只有连接在,就不用再做鉴权&lt;/li&gt;
&lt;li&gt;未来可能会有ACL机制,比如某些用户并没有&lt;code&gt;config set dir&lt;/code&gt;的权限&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>How 2015 flies</title>
      <link>https://lawulu.github.io/post/%E6%88%91%E7%9A%842015/</link>
      <pubDate>Sun, 03 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E6%88%91%E7%9A%842015/</guid>
      <description>

&lt;p&gt;光阴者,百代之过客也.在我年少畅想未来时候,2015从来都是遥远的,而现在,不管曾经多少梦想不管曾经多少遗憾,2015已经彻底逝者如斯夫了.这一年,发生了什么？&lt;/p&gt;

&lt;h2 id=&#34;时间线&#34;&gt;时间线&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;年初S整个公司业绩不好,加上项目被cut off,一直想着换工作.后来又做了半年新项目,反而更加坚定了离开的念头.&lt;/li&gt;
&lt;li&gt;6月份有了新去处,但是被S的一个领导拉去现在公司C,中间断断续续好几个机会都是S公司的人脉,总的来说,虽然一直后悔说应该早点离开,但在S公司还是非常愉快和值得留念的.&lt;/li&gt;
&lt;li&gt;在公司C三个月之后,C公司发生大的人事变动,继年初之后,再一次见识到了职场的波澜壮阔.无愧于心,专心做好自己的事,提高自己才是王道.&lt;/li&gt;
&lt;li&gt;9月份,许久的期盼之后,媳妇终于确认怀孕.备孕育儿这事是提升夫妻和谐关系增加家庭责任感的一件重要事情.&lt;/li&gt;
&lt;li&gt;下半年一直想着提升生活质量,开始开车上下班,但是每天因为车位问题,还有车没什么智能辅助设备,诸多不便,一点也没有体会到驾驶的乐趣；眼看着房价一点点涨,却顾前顾后没有换房的勇气,到年底房价彻底涨起来之后,终于绝了换房的念头.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;从微博与微信回忆2015&#34;&gt;从微博与微信回忆2015&lt;/h2&gt;

&lt;h3 id=&#34;年初感慨颇多&#34;&gt;年初感慨颇多&lt;/h3&gt;

&lt;p&gt;感慨常立志：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;其实这个时候最有价值的不是什么下决心做新东西,而是那些过去已经开始值得保持下去的旧东西&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;感慨自己：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;这个世界上自信与真诚的人真是太少了！ 对自己要求太完美,不面对现实,喜欢做鸵鸟.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;感慨裁员风波的公司：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;各路神仙上蹿下跳,各路跳梁粉墨登场,各色人等各显神通.随波逐流或奋力跃出,劳燕分飞稻粱谋！&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;柴静雾霾调查&#34;&gt;柴静雾霾调查&lt;/h3&gt;

&lt;p&gt;记得中学政治课本一直在笑话资本主义先污染后治理,奥运前夕有运动员说北京空气差还跟风去骂.在现在的政治体制下,如果执政者顾虑重重并无动于衷,屁民只能逆来顺受麻木不仁.&lt;/p&gt;

&lt;h3 id=&#34;平凡世界电视剧版播出&#34;&gt;平凡世界电视剧版播出&lt;/h3&gt;

&lt;p&gt;电视剧有亮点,但跟书中的感觉差距很大.初高中时候读了平凡有两遍以上,印象中,书中对官宦阶级小姐的YY和对爱读书的自傲,满足了在小城长大的我的很多不切实的幻想.事实上,路遥自己的人生比孙少平们更精彩.&lt;/p&gt;

&lt;h3 id=&#34;父亲65岁生日&#34;&gt;父亲65岁生日&lt;/h3&gt;

&lt;p&gt;仓促回郑,深深觉得现代化过程中,我们欠父母的太多太多.
14年11月的感慨：
&amp;gt;上一辈的痛苦和烦恼:三分之一是因为时运不济,遇到的通过个人努力就能抓住的机会太少；三分之一是因为贫穷,很长一段生命都在为温饱而挣扎；三分之一是因为对家庭对亲人付出太多.&lt;/p&gt;

&lt;p&gt;之前看了&lt;a href=&#34;http://www.douban.com/note/468023670/&#34;&gt;三毛父亲给三毛的信&lt;/a&gt;,印象颇深.&lt;/p&gt;

&lt;h3 id=&#34;尤文打入欧冠决赛&#34;&gt;尤文打入欧冠决赛&lt;/h3&gt;

&lt;p&gt;有机会,实力差距太明显.&lt;/p&gt;

&lt;h3 id=&#34;全民创业&#34;&gt;全民创业&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;昨天见了一个做实业的老板,在自己花钱做移动互联网.说实业利润下降,说听到国家互联网+的口号很害怕都进来&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;来到现在公司也是受全民创业风潮的影响,事实上我感觉市面上80%的APP都是垃圾.真正能提高生活质量和效率的APP在哪里？&lt;/p&gt;

&lt;h3 id=&#34;新公司&#34;&gt;新公司&lt;/h3&gt;

&lt;p&gt;新的环境,新的同事,新的挑战&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;共事不是要证明自己比别人优秀,而是双赢.&lt;/p&gt;

&lt;p&gt;反思不是要找理由去说明自己做对了&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;母亲的来电&#34;&gt;母亲的来电&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;昨天各种出事,忙得晕头转向,突然接到母亲电话,问关于QQ的一个简单问题.突然觉得,什么是生活呢？(8.24)&lt;/p&gt;

&lt;p&gt;浑浑噩噩中,在这个世界上只有两种东西最能震撼人们的心灵,一是与老家的联系;二便是我们头顶上灿烂的雾霾.(12.1)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;股市和房事-经济头脑&#34;&gt;股市和房事,经济头脑&lt;/h3&gt;

&lt;p&gt;年初稍赚了一笔,但是年中3000点时候没有回去.&lt;/p&gt;

&lt;p&gt;今年也没有换房.前面有12年的教训,今年又是身边好几个人买房.之前也偶尔在关注房价,小区的房价从300W到350W,自己关注的几套房涨的涨卖的卖,这都是实实在在发生的事,但是执行力一点也没有.
&amp;gt;执行力.一定要与有经济头脑的人为伍.虽然自称世界观已经稳定,但是可以学习的东西多着呢.&lt;/p&gt;

&lt;h3 id=&#34;电影老炮儿&#34;&gt;电影老炮儿&lt;/h3&gt;

&lt;p&gt;这片上映以来好评如潮,直接让我觉得自己三观不正了.还好这几天批评的多起来了.&lt;/p&gt;

&lt;p&gt;其实不是价值观多样化的问题,而是实在觉得这片的编剧太粗制滥造,活活把对手写成脑残加傻逼了.
拿《火星救援》来说,想办法在火星上种土豆,可以把九几年的火星探测器给加进来..老炮儿的编剧不是做作的明显就是完全不合逻辑.&lt;/p&gt;

&lt;h3 id=&#34;开车&#34;&gt;开车&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;张爱玲说过,出名要趁早.其实很多事情都是这样.之前一直对开车这件事比较抵触,从去年拿到车,一直到今年11月份趁着大屯路封站才开始开.&lt;/li&gt;
&lt;li&gt;感觉已经很多年没有新技能get√了.上一次还是学玩三国杀？自己看python和Android都是半途而废.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;

&lt;p&gt;对父母和家庭有亏欠,工作不够走心,在与赚钱能力无关东西上投入的精力太多.&lt;/p&gt;

&lt;p&gt;一大波聪明的小孩毕业进入BAT,一大波努力的老码农转行做互联网.现在机会很好,工作比较宽松,希望2016能真心喜欢并投入到与赚钱能力有关的事业中去.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一次Ajax上传文件的调试过程</title>
      <link>https://lawulu.github.io/post/%E4%B8%80%E6%AC%A1Ajax%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E7%9A%84%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Sat, 19 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E4%B8%80%E6%AC%A1Ajax%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E7%9A%84%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B/</guid>
      <description>

&lt;p&gt;很久不做Web了,帮一小弟解决的一个问题.发现新人解决问题都是在Search and Try,据他说无脑搜了很久,但是不会利用Chrome,也不会分析问题.&lt;/p&gt;

&lt;h2 id=&#34;现象和代码&#34;&gt;现象和代码&lt;/h2&gt;

&lt;h3 id=&#34;js端&#34;&gt;Js端&lt;/h3&gt;

&lt;p&gt;使用的FormData&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var formData = new FormData();
    var actionUrl = &amp;quot;/report/agentUpload&amp;quot;;
    var form = new FormData();
    form.append(&amp;quot;file&amp;quot;, $(&amp;quot;#reportFile&amp;quot; )[0]);

    var xhr = new XMLHttpRequest();
    xhr.open(&amp;quot;post&amp;quot;, actionUrl, true);
    xhr.onload = function () {
         alert(&amp;quot;上传完成!&amp;quot;);
    };

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;server端&#34;&gt;Server端&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;public String upload(HttpServletRequest request, @RequestParam(value=&amp;quot;file&amp;quot;,required = true) MultipartFile file, ModelMap model)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是就是取不到,报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Required MultipartFile parameter &#39;file&#39; is not present
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;server端的问题&#34;&gt;Server端的问题？&lt;/h2&gt;

&lt;p&gt;是否发到了Server？&lt;/p&gt;

&lt;p&gt;看Chrome Network面板里面这次请求的Request：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;------WebKitFormBoundaryNLPhxKE21THaBaN1
Content-Disposition: form-data; name=&amp;quot;file&amp;quot;

[object HTMLInputElement]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;貌似是正确的,在Server端确认一下,将参数加上required=false
查看request:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;multipartParameters = {HashMap@8882}  size = 1
multipartParameterContentTypes = {HashMap@8883}  size = 1
multipartFiles = {LinkedMultiValueMap@8884}  size = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Request里面有东西,但是multipartFiles没有东西……&lt;/p&gt;

&lt;p&gt;&lt;em&gt;其实这时候应该已经看出问题了,因为那个值是一个String,但是没注意,自己盲目以为只要带multipartParameters就是文件&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;debug到CommonsMultipartResolver的resolveMultipart方法,里面有这段判断&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;protected MultipartParsingResult parseFileItems(List&amp;lt;FileItem&amp;gt; fileItems, String encoding) {
		MultiValueMap&amp;lt;String, MultipartFile&amp;gt; multipartFiles = new LinkedMultiValueMap&amp;lt;String, MultipartFile&amp;gt;();
		Map&amp;lt;String, String[]&amp;gt; multipartParameters = new HashMap&amp;lt;String, String[]&amp;gt;();
		Map&amp;lt;String, String&amp;gt; multipartParameterContentTypes = new HashMap&amp;lt;String, String&amp;gt;();

		// Extract multipart files and multipart parameters.
		for (FileItem fileItem : fileItems) {
			if (fileItem.isFormField()) {
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果是false…就往MultipartFile里面填值.
难道是Content-type的问题？&lt;/p&gt;

&lt;h3 id=&#34;去js端&#34;&gt;去Js端&lt;/h3&gt;

&lt;p&gt;先找到如何打印Formdata的：
&lt;a href=&#34;http://stackoverflow.com/questions/17066875/how-to-inspect-formdata&#34;&gt;http://stackoverflow.com/questions/17066875/how-to-inspect-formdata&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (var pair of formData.entries()) {
    console.log(pair[0]+ &#39;, &#39; + pair[1]); 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打印的东西是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file, [object HTMLInputElement]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;决定采用原始的document.getElementById(&amp;ldquo;reportFile&amp;rdquo;).files[]&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lastModifiedDate: Tue Dec 20 2015 10:39:39 GMT+0800 (CST)name: &amp;quot;工作簿1.xlsx&amp;quot;size: 23168type: &amp;quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet&amp;quot;webkitRelativePath: &amp;quot;&amp;quot;__proto__: File

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终发现问题：
应该用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; $(&amp;quot;#reportFile&amp;quot; )[0].files[0]

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;盲目的去搜索其实非常浪费时间&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;要善用Chrome Console&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;chrome的一些调试技巧&#34;&gt;Chrome的一些调试技巧&lt;/h2&gt;

&lt;h3 id=&#34;如何找到对应的元素触发的function&#34;&gt;如何找到对应的元素触发的function？&lt;/h3&gt;

&lt;p&gt;可以在EventListerner里面把Click当做断点，也可以点击某个元素，找到对应监听的EventListener,或者对某一个片dom点击&lt;code&gt;Break on subtree modification&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;缓存相关&#34;&gt;缓存相关&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;强制刷新 cmd+shift+r&lt;/li&gt;

&lt;li&gt;&lt;p&gt;可以在设置中禁止缓存&lt;/p&gt;

&lt;h3 id=&#34;console&#34;&gt;console&lt;/h3&gt;

&lt;p&gt;在某个页面，可以在console页面随时调试,甚至可以执行函数：&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;pre&gt;&lt;code&gt;$(&#39;.choose_endcard&#39;).click()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;But,为什么Xpath选择的不能调用Click…&lt;/p&gt;

&lt;h3 id=&#34;setting里面可以对console-log加上timestamp&#34;&gt;Setting里面可以对console.log加上Timestamp&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>一个诡异的Data source is closed问题</title>
      <link>https://lawulu.github.io/post/%E4%B8%80%E4%B8%AA%E8%AF%A1%E5%BC%82%E7%9A%84Data%20source%20is%20closed%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E4%B8%80%E4%B8%AA%E8%AF%A1%E5%BC%82%E7%9A%84Data%20source%20is%20closed%E9%97%AE%E9%A2%98/</guid>
      <description>

&lt;h3 id=&#34;问题由起&#34;&gt;问题由起&lt;/h3&gt;

&lt;p&gt;因为某些问题(这个问题稍后再提),将线上的DBCP版本从1.4升级到2.1,大概扫了一下官方文档,没有迁移指南,只是几个属性名称变了,感觉问题不大,直接升级.升级之后,UT一下,通过.但是上线之后一直报下面错误：
&amp;gt;Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Data source is closed
    at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:23)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:107)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:98)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:386)
    &amp;hellip; 43 more&lt;/p&gt;

&lt;h3 id=&#34;问题背景&#34;&gt;问题背景&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;项目因为需要动态切换数据源,使用的是++AbstractRoutingDataSource++&lt;/li&gt;

&lt;li&gt;&lt;p&gt;需要动态切换的数据源比较多,项目初始化时候通过++BeanDefinitionBuilder++来根据数据库配置动态创建数据源,而报错的连接正是动态生成的的数据源.&lt;/p&gt;

&lt;h3 id=&#34;问题定位&#34;&gt;问题定位&lt;/h3&gt;

&lt;h4 id=&#34;为什么ut测试成功&#34;&gt;为什么UT测试成功&lt;/h4&gt;

&lt;p&gt;原来是UT的时候,因为配置文件,测试其实走的是++AbstractRoutingDataSource++的默认的数据源,并没有走动态生成的数据源&lt;/p&gt;

&lt;h4 id=&#34;怀疑是参数问题或者其他原因&#34;&gt;怀疑是参数问题或者其他原因&lt;/h4&gt;

&lt;p&gt;只设置JDBC Url,依旧报错；换成dbcp,不报错.&lt;/p&gt;

&lt;h4 id=&#34;abstractroutingdatasource的问题&#34;&gt;AbstractRoutingDataSource的问题？&lt;/h4&gt;

&lt;p&gt;使用XML配置,没有问题&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;至此,基本确认是++DBCP2++和++BeanDefinitionBuilder++&lt;/strong&gt;的问题&lt;/p&gt;

&lt;h3 id=&#34;查看源码和debug&#34;&gt;查看源码和Debug&lt;/h3&gt;

&lt;h4 id=&#34;basicdatasource-dbcp1和2有什么区别&#34;&gt;BasicDataSource DBCP1和2有什么区别？&lt;/h4&gt;

&lt;p&gt;DBCP2实现了更多的接口：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class BasicDataSource implements DataSource, BasicDataSourceMXBean, MBeanRegistration, AutoCloseable 

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看dbcp2创建链接和销毁的地方&#34;&gt;查看DBCP2创建链接和销毁的地方&lt;/h4&gt;

&lt;p&gt;是没有Create Connection还是什么时候被Close了？
被Close了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
		this.beanDefinitionMap.put(beanName, beanDefinition);

		if (oldBeanDefinition != null || containsSingleton(beanName)) {
			resetBeanDefinition(beanName);
		}
		
		
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;protected void resetBeanDefinition(String beanName) {
		// Remove the merged bean definition for the given bean, if already created.
		clearMergedBeanDefinition(beanName);

		// Remove corresponding bean from singleton cache, if any. Shouldn&#39;t usually
		// be necessary, rather just meant for overriding a context&#39;s default beans
		// (e.g. the default StaticMessageSource in a StaticApplicationContext).
		destroySingleton(beanName);

		// Reset all bean definitions that have the given bean as parent (recursively).
		for (String bdName : this.beanDefinitionNames) {
			if (!beanName.equals(bdName)) {
				BeanDefinition bd = this.beanDefinitionMap.get(bdName);
				if (beanName.equals(bd.getParentName())) {
					resetBeanDefinition(bdName);
				}
			}
		}
	}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;原来Spring创建Bean的时候会检查是否有oldBeanDefinition,如果有则销毁之.而DBCP2实现了AutoCloseable接口,在这里直接被Close了.&lt;/p&gt;

&lt;h4 id=&#34;为什么有oldbeandefinition&#34;&gt;为什么有oldBeanDefinition？&lt;/h4&gt;

&lt;p&gt;为了支持另一种类型的数据源,引入了一个Bug,会在Spring BeanFactory里面引入重复的定义,因为在AbstractRoutingDataSource中是正确的,所以一直没有发现这个问题.第二次会销毁上次的Bean.
其实在DBCP1时候,也会销毁,但是因为在动态定义的时候没有定义destroy-method=&amp;ldquo;close&amp;rdquo;,其实会引起内存的泄露？&lt;/p&gt;

&lt;p&gt;结论：很多看似运行完好的软件其实都危机四伏..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scrapy</title>
      <link>https://lawulu.github.io/post/Scrapy%E5%88%9D%E7%AA%A5/</link>
      <pubDate>Thu, 15 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Scrapy%E5%88%9D%E7%AA%A5/</guid>
      <description>

&lt;p&gt;最近出于兴趣看了一下Scrapy.第一次仔细研究一个Python框架,先说结论,爬虫分为两种,一种是贪婪爬虫,最常用的就是搜索引擎,看见Url就爬.另外一种是专业爬虫,类似于网络小数定期更新,价格比对.Scrapy适合做第二种.Scrapy专心做爬取逻辑,其优势是框架比较成熟,各种插件比较全.如果真正做一个工业化的产品,Scrapy远远不够,还要攒很多东西进来.其实如果对&lt;code&gt;requests&lt;/code&gt;和&lt;code&gt;beautifulsoup&lt;/code&gt;熟悉,直接上这俩就挺好的.&lt;/p&gt;

&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;Scrapy其实是一个很轻量级或者简单的框架.几个概念：
1. &lt;code&gt;Request&lt;/code&gt;,&lt;code&gt;Response&lt;/code&gt;,顾名思义,对应的就是网络的请求和响应.
2. &lt;code&gt;Item&lt;/code&gt;或者python dict,对应的是爬取到的结果.
3. &lt;code&gt;Pipeline&lt;/code&gt;对Item的处理.
4. &lt;code&gt;Selector&lt;/code&gt;对应的是对HTML的处理
5. &lt;code&gt;Middleware&lt;/code&gt;相当于Filter,分两种,一种是针对Spider,一种针对网络连接
6. &lt;code&gt;Scheduler&lt;/code&gt;一个深度优先的队列
7. &lt;code&gt;Feed&lt;/code&gt; 官方提供的json或者json line的输出
8. &lt;code&gt;meta&lt;/code&gt; 可以在多个Spider之间传输数据&lt;/p&gt;

&lt;p&gt;其实把文档看一遍,下一个demo,很快就可以跑起来.&lt;/p&gt;

&lt;p&gt;看图其实很清楚：
&lt;img src=&#34;https://lawulu.github.io/iimg/scrapy.png&#34; alt=&#34;Scrapy Arch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从StartRequest开始,不停的返回Item或者返回Request,如果返回Item,就发到Pipeline去处理,返回Request,经过Callback处理之后,直到所有的Request都变成Item.正所谓,世界是属于Request,归根结底还是属于Item的.&lt;/p&gt;

&lt;h2 id=&#34;简单示例&#34;&gt;简单示例&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;import scrapy
class ZhihuSpider(scrapy.Spider):
    name = &amp;quot;zhihu&amp;quot;
    start_urls = [
        &#39;https://www.zhihu.com/explore&#39;,
    ]

    def parse(self, response):
        # self.logger.info(&amp;quot;------zzhon中国&amp;quot;)

        for feed in response.css(&#39;.recommend-feed&#39;):
            link = response.urljoin(feed.css(&#39;a::attr(href)&#39;).extract_first());
            yield scrapy.Request(link,callback=self.parse_content)
           

##!!!  print response.css(&#39;#zh-question-detail &amp;gt; div&#39;).extract()[0].encode(&#39;utf-8&#39;)

    def parse_content(self,response):
        yield {
            &#39;title&#39;:response.css(&#39;#zh-question-title &amp;gt; h2 &amp;gt; a::text&#39;).extract_first(),
            &#39;content&#39;:response.css(&#39;#zh-question-detail &amp;gt; div::text&#39;).extract(),
            &#39;link&#39;:response.url
        }

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然这个示例跑起来之前,需要改一些配置文件和设置User-agent…&lt;/p&gt;

&lt;h2 id=&#34;吐槽&#34;&gt;吐槽&lt;/h2&gt;

&lt;p&gt;Java出身的程序员的吐槽… 不用在意😜&lt;/p&gt;

&lt;h3 id=&#34;日志只打印unicode问题&#34;&gt;日志只打印Unicode问题&lt;/h3&gt;

&lt;p&gt;Debug和监控起来非常不方便,我看官方把这个issue当做wont fix了,强烈推荐直接上Python3.对非英文世界来说,Python2下scrapy shell简直没了存在的必要…&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2015-10-14 23:25:54 [scrapy] DEBUG: Scraped from &amp;lt;200 https://www.zhihu.com/question/29218955/answer/41797438&amp;gt; 
{&#39;content&#39;: [u&#39;\u666e\u6d31\u5728\u8fc7\u53bb\u5e94\u8be5\u662f\u4e0d\u4e0a\u53f0\u9762\u7684\u5427\uff1f\u4e5f\u6ca1\u95ee\u662f\u4e0d\u662f\u5c31\u95ee\u4e3a\u4ec0\u4e48\u4e86\uff0c\u5982\u679c\u95ee\u9898\u6709\u9519\u8bef\uff0c\u8bf7\u6307\u6b63&#39;], &#39;link&#39;: &#39;https://www.zhihu.com/question/19258955/answer/42797438&#39;, &#39;title&#39;: u&#39;\u666e\u6d31\u7531\u539f\u6765\u4e0d\u4e0a\u53f0\u9762\u7684\u8fb9\u9500\u8336\u5230\u5982\u4eca\u53d7\u5230\u5e7f\u5927\u8336\u53cb\u559c\u7231\u7684\u8336\u7c7b\uff0c\u9664\u4e86\u7092\u4f5c\u5916\uff0c\u666e\u6d31\u7684\u5de5\u827a\u6216\u8005\u8d28\u91cf\u6709\u4e86\u5f88\u5927\u8fdb\u6b65\u5417\uff1f&#39;} 

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scheduler太弱&#34;&gt;Scheduler太弱&lt;/h3&gt;

&lt;p&gt;自带的scheduler只能深度优先和广度优先,官方推荐是自家的scrapyd,稍微了解了下,应该是启动时候把任务分给多个进程,进程之间好像没法交互.&lt;/p&gt;

&lt;h3 id=&#34;spider-request之间很难协同&#34;&gt;Spider/Request之间很难协同&lt;/h3&gt;

&lt;p&gt;很多时候我们需要某几个Request应该在一个组里面,同一个组的Request可以共用Cookie,共用代理.这类的需求可以通过meta机制来实现…由于Scrapy的Request是无脑yield出来的,实现出来肯定很丑陋.&lt;/p&gt;

&lt;h3 id=&#34;callback-hell&#34;&gt;Callback hell&lt;/h3&gt;

&lt;p&gt;通过Callback来绑定处理方法,入口和可测试性很差,怪不得要加入Contract机制&lt;/p&gt;

&lt;h3 id=&#34;容错&#34;&gt;容错&lt;/h3&gt;

&lt;p&gt;容错机制很少,需要把Task持久化,官方提供的持久化到disk的方案感觉很初级很粗糙.&lt;/p&gt;

&lt;h2 id=&#34;splash&#34;&gt;Splash&lt;/h2&gt;

&lt;p&gt;Pyspider是用的&lt;code&gt;PhantomJS&lt;/code&gt;,Scrapy提供了一个基于Docker和Lua的Splash.
这货的问题是Splash没有保持渲染状态的方法,对于复杂的JS交互,一般的做法是一个lua脚本执行很多次,最后返回所有的结果.这样爬取的颗粒比较大,如果中间出现异常,不好处理,而且调用&lt;code&gt;splash::wait()&lt;/code&gt;总感觉不靠谱,没有提供Dom加载之后的回调吗？&lt;/p&gt;

&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;

&lt;p&gt;Splash可以执行Lua脚本,官方封装了Splash类,可以和JS交互.这样,就可可以找到Dom中的Button,直接调用click事件,然后返回某些DOM中的Html或者Json.&lt;/p&gt;

&lt;h3 id=&#34;lua&#34;&gt;Lua&lt;/h3&gt;

&lt;p&gt;Lua 很值得一学,Nginx,游戏引擎,Redis都在用……
快速入门：&lt;a href=&#34;http://tylerneylon.com/a/learn-lua/&#34;&gt;http://tylerneylon.com/a/learn-lua/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lua稍微复杂并且可以玩出花的内置机制就是Metatable了,可以重载对字典(对象)各种操作符.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>