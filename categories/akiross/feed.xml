<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>璐濒殉漂流记</title>
    <link>https://lawulu.github.io/categories/akiross/feed/index.xml</link>
    <description>Recent content on 璐濒殉漂流记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <atom:link href="https://lawulu.github.io/categories/akiross/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>程序员必备七种武器</title>
      <link>https://lawulu.github.io/post/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%E4%B8%83%E7%A7%8D%E6%AD%A6%E5%99%A8/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%85%E5%A4%87%E4%B8%83%E7%A7%8D%E6%AD%A6%E5%99%A8/</guid>
      <description>

&lt;p&gt;&lt;em&gt;本篇为公众号&lt;code&gt;码农翻身&lt;/code&gt;的约稿&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;科学上网&#34;&gt;科学上网&lt;/h2&gt;

&lt;p&gt;从服务器芯片到底层协议，从W3C技术标准到github各种开源项目，IT技术绝大部分都起源于墙外，而Google是检索这些第一手技术的最好的手段，没有之一。所以对码农来说，可以自由的浏览是非常有必要的。&lt;/p&gt;

&lt;p&gt;有很多种科学上网方式，笔者推荐自己买海外主机搭建,可以和亲近朋友一起使用一台。除了常用的SS之外，SSH的socks转发是最简单的方式了。&lt;/p&gt;

&lt;p&gt;例如笔者常用的一个shell：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#!/bin/sh
nohup ssh  -ND 3128 user@jumpserver &amp;amp;
/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome  Chrome --proxy-server=&amp;quot;socks5://localhost:3128&amp;quot; --host-resolver-rules=&amp;quot;MAP * 0.0.0.0 , EXCLUDE localhost&amp;quot; --user-data-dir=/tmp/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这个shell在Mac下启动一个Chrome进程，该进程完全以jumpserver的网络去访问互联网，这样在这个Chrome内访问公司云主机内网的各种服务非常方便。&lt;/p&gt;

&lt;h2 id=&#34;剪贴板&#34;&gt;剪贴板&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://blog.todamax.net/wp-content/uploads/2016/03/copy-paste-from-stack-overflow.jpeg&#34;&gt;http://blog.todamax.net/wp-content/uploads/2016/03/copy-paste-from-stack-overflow.jpeg&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;相信大家最常用的快捷键就是复制和粘贴了。
假如你刚刚从Wiki的设计文档把一个API的URL复制下来准备写代码；发现经常聊天的一个技术群弹出一个消息，有个妹子问一个技术问题，凭借自己对技术的感觉很快在Stackoverflow搜到了答案，
赶紧把答案复制过去；突然又收到产品群发的一个邮件需要你去撕逼，写了几句之后，觉得某个措辞应该放到后面，刚剪切了第一句；经理在IM上让你把某个需求的Jira链接发给他..你如果经常遇到这种情况，首先考虑的应该是把所有的打扰都屏蔽掉，如果做不到，那就安装一个剪贴板工具吧。&lt;/p&gt;

&lt;p&gt;Windows下推荐ditto，Mac下推荐Alfred自带的。顺便提一下，类似Mac下的Alfred这种工具（Windows下的有TotalCommander），如果能研究透彻，会极大的提高工作效率。&lt;/p&gt;

&lt;h2 id=&#34;抓包&#34;&gt;抓包&lt;/h2&gt;

&lt;p&gt;现在很多产品和需求都需要通过网络与用户或其他服务打交道。抓包工具可以把自己交付物当做一个黑盒，去发现和定位问题。Windows下的Fiddler，Mac下推荐Charles都非常强大。这两者通过安装证书，甚至可以直接抓取Https的网络。&lt;/p&gt;

&lt;p&gt;基于Web的应用，也可以直接考虑浏览器的开发者工具。例如，Chrome的开发者工具就非常强大：可以直接找到元素的XPath，在Console运行JS代码，通过修改元素的文本来P图。&lt;/p&gt;

&lt;p&gt;如果想做更深层次的抓包，可以研究下Wireshark。&lt;/p&gt;

&lt;h2 id=&#34;文本编辑器&#34;&gt;文本编辑器&lt;/h2&gt;

&lt;p&gt;程序员经常要跟各种日志和数据打交道，一个熟悉的文本编辑器可以事半功倍。&lt;/p&gt;

&lt;p&gt;笔者比较常用的功能有列模式，例如把一些数据直接编辑成SQL；正则替换，例如从不太标准的日志中提取自己所需的内容。&lt;/p&gt;

&lt;p&gt;文本编辑器免费的有Sublime Text/Atom,商业软件有UltraEdit等。另外还有一种基于终端的文本编辑器，例如Nano/Vim/Emacs。如果从事Server开发，掌握这些编辑器的查找、修改、行号等功能是非常有必要的。&lt;/p&gt;

&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;

&lt;p&gt;在这个信息爆炸的时代，搜索引擎有时候也捉襟见肘。子曰：&amp;rdquo;吾日三省吾身&amp;rdquo;，做笔记是一个非常好的反省自己的手段，对每天的收获进行记录和整理，也方便后续快速解决类似问题。市面上的笔记产品大同小异，笔者一直使用有道云笔记：支持MarkDown语法，免费，跨平台。
另外，思维导图也是一个非常好的整理自己知识的工具。&lt;/p&gt;

&lt;h2 id=&#34;脚本语言&#34;&gt;脚本语言&lt;/h2&gt;

&lt;p&gt;假如突然接到一个这样的临时需求：需要给客户端提供一个模拟服务器，根据请求内容的不同，返回相应的Json。这个需求用Python SimpleHTTPServer十几行代码就能实现。很多类似的临时需求，还有需要快速验证的想法，以及粘合多个系统，脚本语言是最合适的。在自己的主力开发语言之外熟悉一门脚本语言做很多事都可以事半功倍，也可以体验到另一种编程文化。&lt;/p&gt;

&lt;p&gt;有很多脚本语言（shell,Ruby,Perl等等）可以选择，笔者推荐Python。Python这些年在很多领域都重新受到追捧。Python有2和3两种，推荐直接上手3，虽然很多老版本服务器系统自带的还是2，但是现在基本上所有的主流库都已经支持Python3了。&lt;/p&gt;

&lt;p&gt;如果单纯的当做一个脚本语言，只需要了解如何处理字符串，常用数据结构，如何处理文件和网络IO,基本就满足日常需求了。&lt;/p&gt;

&lt;p&gt;另外推荐一下Jupyter Notebook，这是一个web版的Python编辑、运行和演示环境(也支持R等其他语言)，可以和shell等环境变量交互。很多人在服务器上直接运行notebook,然后在本地web端调试python程序。&lt;/p&gt;

&lt;h2 id=&#34;自己的codebase&#34;&gt;自己的CodeBase&lt;/h2&gt;

&lt;p&gt;将自己Coding经验提炼为一个CodeBase。经常需要的用模块，如Web框架、模板引擎、Http请求、单元测试以及Mock、Cache、调度、Metric、时间处理、安全、日志、XML/Excel解析等等，每一个模块都有三四种可以选择的技术，选择一个自己熟悉的，构建自己的软件开发栈，这样遇到各种需求都能快速基于自己的CodeBase的实现。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>数据需要收集哪些数据</title>
      <link>https://lawulu.github.io/post/%E6%95%B0%E6%8D%AE%E9%9C%80%E8%A6%81%E6%94%B6%E9%9B%86%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE/</link>
      <pubDate>Thu, 15 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E6%95%B0%E6%8D%AE%E9%9C%80%E8%A6%81%E6%94%B6%E9%9B%86%E5%93%AA%E4%BA%9B%E6%95%B0%E6%8D%AE/</guid>
      <description>

&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;最近线上遇到一些问题，分析起来还是要抓瞎，完全不知道怎么去定位。只能从代码去分析&amp;hellip;觉得之前的设计的数据收集太简单了，只是以报表需求为导向设计的。那我们还需要收集哪些数据呢？&lt;/p&gt;

&lt;h2 id=&#34;能解释业务的数据&#34;&gt;能解释业务的数据&lt;/h2&gt;

&lt;h3 id=&#34;所有业务要串起来&#34;&gt;所有业务要串起来&lt;/h3&gt;

&lt;p&gt;业务有三条线：
- Active
- Config
- Preload-&amp;gt;Impression-&amp;gt;Event-&amp;gt;Click-&amp;gt;Install&lt;/p&gt;

&lt;p&gt;改动：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;最核心的广告生命周期是否可以用一个Id呢？如果不能，每一步要讲上一步的id给带上来。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;CDN的下载要带上一个preloadId，然后开启参数过滤，通过关联preloadId将下载流程也关联到核心业务上去。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;重复Id上报的问题&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;server日志&#34;&gt;Server日志&lt;/h3&gt;

&lt;p&gt;为了帮助运营快速的定位业务问题，如为什么某些App的填充低？为什么Erpm最低的某个Campaign还拿到了量？可以考虑将Serving的日志和业务关联起来。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ELK要用起来，亦可以调研一下阿里的日志服务&lt;/li&gt;
&lt;li&gt;规范Server输出，尤其是Filter广告时候，要将挑选广告失败的原因记录到日志里面&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;可追溯每个客户端的行为的数据&#34;&gt;可追溯每个客户端的行为的数据&lt;/h2&gt;

&lt;p&gt;最近几个痛点：流量端说我们的填充率对低，而我们报表的填充率非常高；点击广告主上报跟服务器上报总是对不上；点击率中有真实点击和误点击区分不开。所以要收集这些数据：
- APP对SDK的接口调用都要记录
- SDK和Server之外的所有交互（点击上报，CDN下载）都要记录
- 以上记录可以通过开关来控制
- EndCard的点击率要能区分点击区域，找到真实的点击率&lt;/p&gt;

&lt;h2 id=&#34;其他数据&#34;&gt;其他数据&lt;/h2&gt;

&lt;p&gt;抓友商的包，发现友商有一个SessionStart和SessionEnd的接口，这个要加上。貌似SessionEnd不准，因为每次进入后台，SDK没有机会发请求到Server。&lt;/p&gt;

&lt;h2 id=&#34;实施&#34;&gt;实施&lt;/h2&gt;

&lt;h3 id=&#34;ab测试准备&#34;&gt;AB测试准备&lt;/h3&gt;

&lt;p&gt;增加一个Header&lt;code&gt;x-clad-tag&lt;/code&gt;,在Config接口下发下去，给用户打标签，并贯彻到整个业务流程&lt;/p&gt;

&lt;h3 id=&#34;上报服务拆分&#34;&gt;上报服务拆分&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Impr,Click等事件上报因为只是记一个数字，要和Preload业务从逻辑和部署上都分开，避免互相干扰&lt;/li&gt;
&lt;li&gt;并且上报地址应该是Preload下发下去，而非写死，并且支持同一事件的多地址上报。这样易于控制，甚至以后可以作弊（按照某人的说法：&amp;rdquo;&lt;code&gt;我们不主动作恶，但是在恶劣的环境下，要有保护自己的手段。&lt;/code&gt;&amp;ldquo;）&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Preload接口和Play接口的兴衰史</title>
      <link>https://lawulu.github.io/post/Preload%E5%92%8CPlay%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%85%B4%E8%A1%B0%E5%8F%B2/</link>
      <pubDate>Thu, 01 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Preload%E5%92%8CPlay%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%85%B4%E8%A1%B0%E5%8F%B2/</guid>
      <description>

&lt;p&gt;通过对业务的深入理解和梳理，来优化架构。先说结论：&lt;strong&gt;Preload的本质是告诉SDK下一次Impression应该展示哪个广告&lt;/strong&gt;。&lt;/p&gt;

&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;

&lt;p&gt;对于Native移动视频广告来说，一方面网络条件所限，另一方面要提升用户和广告主的体验，播放广告基本都是以预加载的形式提前把广告加载完成。这个特性让Ad Serving的流程大大不同。&lt;/p&gt;

&lt;h2 id=&#34;第一版的做法&#34;&gt;第一版的做法&lt;/h2&gt;

&lt;h3 id=&#34;提供了两个接口&#34;&gt;提供了两个接口:&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Preload,用来告诉SDK有哪些广告可以下载，然后告诉SDK开始下载，一般是三到五条。&lt;/li&gt;
&lt;li&gt;Play，在SDK有曝光机会的时候，SDK将已经预加载完成的广告告诉Server，Server从中挑出可播的广告。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;问题&#34;&gt;问题&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Preload和Play两个接口时间上有间隔，在另一个时间点，各种条件已经变化了，需要重新挑选广告。所以同一次曝光机会，可能需要挑选两次。&lt;/li&gt;
&lt;li&gt;Play接口的响应时间要求很高，客户端的网络又不稳定。&lt;/li&gt;
&lt;li&gt;整个链路太长，又有些条件不可控，所以Ad Serving的逻辑很难优化。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;梳理业务-重新定义&#34;&gt;梳理业务，重新定义&lt;/h2&gt;

&lt;h3 id=&#34;其他部门角度&#34;&gt;其他部门角度&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;对商务来说，尾量可以接受，甚至非常正常。这意味着，各种定向控制并不需要那么严谨。&lt;/li&gt;
&lt;li&gt;对运营来说，CDN的消耗相比转化率的提高并不重要，更迫切需要一个可以快速干扰Ranking的办法。&lt;/li&gt;
&lt;li&gt;对产品来说，需要让事情简单化。我们的Preload的挑选广告就对应传统Ad产品中的那次挑选广告就OK。&lt;/li&gt;
&lt;li&gt;对数据来说，填充率的计算需要和流量方匹配。对应第一版来说，填充率，是用Play接口的成功返回/Play接口的调用。&lt;/li&gt;
&lt;li&gt;对技术来说，Play接口要求太高，优化起来太困难。&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;那么&#34;&gt;那么&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Preload接口挑选广告，Play接口只做Impression的上报&lt;/li&gt;
&lt;li&gt;激进的来说，每次Preload只预加载一次，播完就删&lt;/li&gt;
&lt;li&gt;在应用启动和每次播放完成之后调用一次Preload&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Play的逻辑前置和合并到Preload里面，Play沦为一个上报接口&lt;/p&gt;

&lt;h2 id=&#34;推而广之&#34;&gt;推而广之&lt;/h2&gt;

&lt;p&gt;SDK模式下，每个接口对userId是否是合法用户的检查也没有意义。&lt;/p&gt;

&lt;p&gt;所谓SDK模式，因为SDK是自家的，流量和费用都是通过商务谈的。API的设计是建立在SDK可控和可以信任的基础之上的。现有架构之下，每次激活相当于获得了一个调用其他API的Token，而这个Token是保存在客户端本地的，所以，没必要去单独Check UserId，
即使检查不通过，SDK自动会去调用用户激活接口，又会得到一个已经激活UserId。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>公司整体架构上的一些思考</title>
      <link>https://lawulu.github.io/post/%E5%85%AC%E5%8F%B8%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E4%B8%8A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</link>
      <pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E5%85%AC%E5%8F%B8%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E4%B8%8A%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/</guid>
      <description>

&lt;h2 id=&#34;server&#34;&gt;Server&lt;/h2&gt;

&lt;h3 id=&#34;性能&#34;&gt;性能&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;流量高峰时候遇到过响应时间过大

&lt;ul&gt;
&lt;li&gt;充分利用WEB服务器性能(例如OpenResty或者Nginx+NgixScirpt），将简单通用的业务逻辑（如签名校验和去重逻辑）前置，降低后端容器的负荷，提高并发和响应&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;客户端重试导致的服务器雪崩

&lt;ul&gt;
&lt;li&gt;部分接口静态化（例如config接口），服务降级，例如直接返回null
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;redis依赖&#34;&gt;Redis依赖&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;太过于依赖Redis

&lt;ul&gt;
&lt;li&gt;引入二级缓存，降低和隔离对Redis的依赖&lt;/li&gt;
&lt;li&gt;Redis数据分只读和读写两种，可以放到两个集群里面&lt;/li&gt;
&lt;li&gt;上Redis集群？&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;阿里云Redis

&lt;ul&gt;
&lt;li&gt;考虑在某些场景用阿里云Redis
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;监控和日志&#34;&gt;监控和日志&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;现在已经有了基于Zabbix的机器性能的监控，需要业务层次的分布式监控系统（例如Cat），方便快速洞察和响应线上问题&lt;/li&gt;
&lt;li&gt;日志统一格式到Json&lt;/li&gt;
&lt;li&gt;ELK需要提到日程了&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;数据&#34;&gt;数据&lt;/h2&gt;

&lt;h3 id=&#34;数据质量&#34;&gt;数据质量&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;使用python grep按小时检查原始日志，来和Hive对比保证数据完整和正确性
&lt;code&gt;
p = subprocess.Popen(&amp;quot;&amp;quot;&amp;quot; cat &amp;quot;&amp;quot;&amp;quot; + file + &amp;quot;&amp;quot;&amp;quot;| grep -avF &#39;[2.3.0]&#39; | grep -aF &#39;[04]&#39;  |  wc -l &amp;quot;&amp;quot;&amp;quot;, shell=True, stdout=subprocess.PIPE );
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;对某些阈值进行报警，例如Preload，没有转化，点击率过低等情况。帮助运营及早洞察线上问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;任务调度&#34;&gt;任务调度&lt;/h3&gt;

&lt;p&gt;现在基于Crontab，缺点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;没有任务依赖关系，通过较长的时间间隔来保证任务的先后顺序。&lt;/li&gt;
&lt;li&gt;重跑起来比较麻烦。&lt;/li&gt;
&lt;li&gt;报警实现起来有点难&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;解决方案：&lt;/p&gt;

&lt;p&gt;根据开源实现，将现有的任务（任务类型主要：shell,hive,sqoop）整合到任务调度系统中。
例如：&lt;a href=&#34;http://azkaban.github.io/azkaban/docs/latest/#new-hive-type&#34;&gt;http://azkaban.github.io/azkaban/docs/latest/#new-hive-type&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;查询引擎&#34;&gt;查询引擎&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;因为某些维度太细（手机型号，城市）报表查询慢

&lt;ul&gt;
&lt;li&gt;为报表预生成数据&lt;/li&gt;
&lt;li&gt;更换查询引擎，如Druid，Kylin？&lt;/li&gt;
&lt;li&gt;Ali RDS是否有优化Mysql（例如引擎）的可能&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;其他&#34;&gt;其他&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;对Serving的支持：数据和Server的界限问题。例如ImprNum per Campaign per app的计数，这个应该放到data还是server？&lt;/li&gt;
&lt;li&gt;分层过多，如何快速响应业务变化？&lt;/li&gt;
&lt;li&gt;如何能快速定位问题？如为什么填充下降了？不填充的原因要列出来。如为什么有些erpm低的拿到的量大？(4G网络下面包体大于100M的不下发， 前面高erpm的经过两轮（第一轮是否在线，第二轮数据网络条件下面包体大小过滤）过滤掉， 正好轮到了1789下发)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;统计维度&#34;&gt;统计维度&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;如何才能将&lt;code&gt;产生转化的意愿和原因&lt;/code&gt;，可视化出来？有效点击（对应安装的点击）？用户观看数？&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>基于Dubbo的Batch项目</title>
      <link>https://lawulu.github.io/post/%E5%9F%BA%E4%BA%8EDubbo%E7%9A%84Batch%E9%A1%B9%E7%9B%AE/</link>
      <pubDate>Tue, 17 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E5%9F%BA%E4%BA%8EDubbo%E7%9A%84Batch%E9%A1%B9%E7%9B%AE/</guid>
      <description>

&lt;p&gt;这个Demo完成于去年，今天把一些敏感信息去掉，放到github上&lt;/p&gt;

&lt;h1 id=&#34;dubbo-batch-demo&#34;&gt;dubbo batch demo&lt;/h1&gt;

&lt;p&gt;包含了一个Batch项目和一个Portal。
依赖当当的DubboX&lt;/p&gt;

&lt;h2 id=&#34;batch&#34;&gt;Batch&lt;/h2&gt;

&lt;p&gt;Batch使用了Spring batch，Quartz，Dubbo
通过自定义的MetaData来管理所有数据&lt;/p&gt;

&lt;h2 id=&#34;portal&#34;&gt;Portal&lt;/h2&gt;

&lt;p&gt;一个实例项目，改造自当当的Elastic-job的Admin Portal，用到lombok和Freemarker&lt;/p&gt;

&lt;h1 id=&#34;项目地址&#34;&gt;项目地址&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/lawulu/dubbo-batch-demo&#34;&gt;https://github.com/lawulu/dubbo-batch-demo&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>广告的Tracking(AdNetwork&#39;s Point of view)</title>
      <link>https://lawulu.github.io/post/%E5%B9%BF%E5%91%8A%E7%9A%84Tracking/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E5%B9%BF%E5%91%8A%E7%9A%84Tracking/</guid>
      <description>

&lt;p&gt;&lt;em&gt;&lt;strong&gt;广告新人的一些感想&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;在移动互联网烧钱大潮中，（传统来说）有流量变现能力只有广告了。当每一次点击都与钱相关时候，机会和伴随机会而来的混乱就出现了。&lt;/p&gt;

&lt;h2 id=&#34;商机&#34;&gt;商机&lt;/h2&gt;

&lt;p&gt;对于移动强CPA广告来说，最大的痛点就是转化的核算和归因。各种第三方平台（友盟，TalkingData，热云……），各种不同的规范……，能否成立的一家Tracking平台，帮助AdNetwork来统一追踪。甚至有了各家的数据之后（因为各家的为了Tracking，都要把DevieId通过平台透传）：可以收钱做优化，因为平台（从整个宏观数据可以看出）知道哪类流量适合哪类推广；也可以卖数据甚至卖流量。其实类似想统一混乱的公司有Appcoach,Affiliate，mediation。。简单写一下我们用的FC.&lt;/p&gt;

&lt;h3 id=&#34;fc的做法&#34;&gt;FC的做法&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;为每一个AdNetwork建立一个Tracking Link，在Dashboard中配置对应的宏和Postback Url。&lt;/li&gt;
&lt;li&gt;提供报表做到小时级别的统一，方便了不同时区的用户。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;归因是怎么做的&#34;&gt;归因是怎么做的&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;渠道包，因为（国内）Android并没有一个强势如AppStore的（混乱之源之一）应用商店，所以就会有渠道包这种东西。之前公司每次上线Android，有专门的应用分发脚本，给不同渠道的包不一样。这样就可以知道各个渠道的推广情况。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;根据设备id归因：对于Android来说国内是IMEI和AndroidId，国外是GAID。iOS比较规范，一般使用IDFA，不过新版iOS用户据说可以关闭广告追踪。详细流程再下面讲。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Fingerprint：大的平台会基于设备的零散数据例如ip,ua，通过数据积累，当遇到没有设备id信息的归因问题时，就用这些零散的数据作为唯一标示确认唯一性。&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Referrer来源：如果应用商店支持，可以传递参数表明自己的渠道信息。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;tracking流程&#34;&gt;Tracking流程&lt;/h2&gt;

&lt;h3 id=&#34;tracking&#34;&gt;Tracking&lt;/h3&gt;

&lt;p&gt;对AdNetwork来说，由于无法知道是否安装完成，所以要通过第三方的平台来完成计费。所以，Tracking一般分为Click上报和Install的Postback。即当用户要下载一个App时候，AdNetwork马上告诉广告主（或者代表广告主的检测平台），快看，我这有个用户点击了，他要安装了！！然后就开始默默的等待..广告主收到一个安装，就会根据安装时候的信息反过来去找是谁上报的，一般会根据设备的信息（混乱之源之一)来匹配。所以上报时候一定要把设备信息给带上。上报分302让客户端上报和S2S对接两种，按下不表。&lt;/p&gt;

&lt;h3 id=&#34;宏替换&#34;&gt;宏替换&lt;/h3&gt;

&lt;p&gt;由于AdNetwork要对接的第三方平台太多，而各家Tracking时候需要的参数是不一样的。（为什么没有一个广告协会之类规范一下？！），所以就会有宏替换这么一个奇特而又奇妙的东西。&lt;/p&gt;

&lt;p&gt;举一个例子：&lt;/p&gt;

&lt;p&gt;假如，归因平台需要一个参数DeviceId，但是归因平台A用的参数是&lt;code&gt;did&lt;/code&gt;，例如&lt;code&gt;http://a.com/tracking?did=XX&lt;/code&gt;, 而归因平台B用的参数是&lt;code&gt;device&lt;/code&gt;，例如&lt;code&gt;http://b.com/tracking?device=XX&lt;/code&gt;。&lt;/p&gt;

&lt;p&gt;AdNetwork并不需要知道每一家归因平台的DeviceId应该怎么上报，只需要提供一批可供替换的变量，让客户自己填。例如DeviceId在AdNetwork的变量是shebeihao，那么上面两家分别填写：&lt;code&gt;http://a.com/tracking?did={shebeihao}&lt;/code&gt;，和&lt;code&gt;http://a.com/tracking?device={shebeihao}&lt;/code&gt;，等上报时候，将这些信息都被AdNetwork替换正确。&lt;/p&gt;

&lt;p&gt;同样的，归因平台也有类似的宏替换的机制，如果AdNetwork的PostBack url是&lt;code&gt;http://ad.com/postback&lt;/code&gt;,那对于归因平台A，Postback url就是&lt;code&gt;http://ad.com/postback?shebeihao={did}&lt;/code&gt;,对于归因平台B，Postback url就是&lt;code&gt;http://ad.com/postback?shebeihao={device}&lt;/code&gt;
归因平台也是，Postback时候，也可以走同样的流程。&lt;/p&gt;

&lt;h2 id=&#34;系统演进&#34;&gt;系统演进&lt;/h2&gt;

&lt;h3 id=&#34;第一版基于参数透传&#34;&gt;第一版基于参数透传&lt;/h3&gt;

&lt;p&gt;并且自己组装了一个customParm,将所有需要的维度而又无法透传的参数组装到一起，回传回来直接根据这些透传参数生成安装报表。&lt;/p&gt;

&lt;p&gt;问题：
- 参数过程某些家解析会出错
- 传递过程中参数容易丢&lt;/p&gt;

&lt;h3 id=&#34;第二版基于clickid查找&#34;&gt;第二版基于ClickId查找&lt;/h3&gt;

&lt;p&gt;只使用ClickId归因&lt;/p&gt;

&lt;p&gt;问题：
- 支持30天回溯的话，对系统压力比较大，需要引入NoSql
- 如果ClickId丢失，基本就丢了&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Redis的安全哲学</title>
      <link>https://lawulu.github.io/post/Redis%E7%9A%84%E5%AE%89%E5%85%A8%E5%93%B2%E5%AD%A6/</link>
      <pubDate>Mon, 15 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Redis%E7%9A%84%E5%AE%89%E5%85%A8%E5%93%B2%E5%AD%A6/</guid>
      <description>

&lt;p&gt;最近看到Redis的作者antirez写的一篇blog: &lt;a href=&#34;http://antirez.com/news/96&#34;&gt;http://antirez.com/news/96&lt;/a&gt;
里面有些东西很有意思.摘录一些观点:&lt;/p&gt;

&lt;h2 id=&#34;为什么redis这么多-安全漏洞&#34;&gt;为什么Redis这么多&amp;rdquo;安全漏洞&amp;rdquo;?&lt;/h2&gt;

&lt;p&gt;作者说经常收到一些Redis不安全的Report,但是大部分Report其实跟Redis没有什么关系或者说对Redis来说无关紧要.因为Redis的绝大多数用户都是将Redis放到一个安全的环境里面,而安全是一个很大的feature,Redis不会为了一小撮用户做开发这么复杂的功能.
&amp;gt;it’s totally insecure to let untrusted clients access the system, please protect it from the outside world yourself&lt;/p&gt;

&lt;h2 id=&#34;一次hack过程&#34;&gt;一次Hack过程&lt;/h2&gt;

&lt;p&gt;安全页面写到: &lt;a href=&#34;http://redis.io/topics/security&#34;&gt;http://redis.io/topics/security&lt;/a&gt;
&amp;gt;the ability to control the server configuration using the CONFIG command makes the client able to change the working directory of the program and the name of the dump file. This allows clients to write RDB Redis files at random paths, that is a security issue that may easily lead to the ability to run untrusted code as the same user as Redis is running&lt;/p&gt;

&lt;p&gt;所以,使用config命令可以往主机的Path写文件,作者展示了这一过程(为防止有些&lt;code&gt;script kiddies cut &amp;amp; paste the attack&lt;/code&gt;,没有直接提供一个脚本,并且还首先备份了当前的数据,这里省略一些无关紧要的步骤):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;生成一对RSA key,并且写到一个文件里面,前后加上换行符
&lt;code&gt;
$ (echo -e &amp;quot;\n\n&amp;quot;; cat id_rsa.pub; echo -e &amp;quot;\n\n&amp;quot;) &amp;gt; foo.txt
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将public key写到一个KV里面
&lt;code&gt;
cat foo.txt | redis-cli -h 192.168.1.11 -x set crackit
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;设置工作目录
&lt;code&gt;
config set dir /Users/antirez/.ssh/
&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;将内存中数据保存到Db文件中
&lt;code&gt;
config set dbfilename &amp;quot;authorized.keys&amp;quot;
save
&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;大功告成!&lt;/p&gt;

&lt;h2 id=&#34;为什么不默认bind-127-0-0-1&#34;&gt;为什么不默认bind 127.0.0.1?&lt;/h2&gt;

&lt;p&gt;事实上,如果启动时候带上默认的配置文件(redis.conf),就不存在这个安全隐患,因为配置文件里面默认是只绑定了Loopback address.既然作者知道这个安全隐患,为什么不默认启用这个配置文件呢?(就像Mysql那样).&lt;/p&gt;

&lt;p&gt;作者的解释是,因为RTFM（Read The Fucking Manual）&lt;/p&gt;

&lt;h2 id=&#34;使用auth&#34;&gt;使用Auth&lt;/h2&gt;

&lt;p&gt;虽然并不能真正解决安全问题..最简单有效的方法就是使用Auth.使用Auth的的几点说明:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;密码要尽可能的复杂,以防被brute force&lt;/li&gt;
&lt;li&gt;Auth的消耗非常少,只是在连接建立时候做一次鉴权,只有连接在,就不用再做鉴权&lt;/li&gt;
&lt;li&gt;未来可能会有ACL机制,比如某些用户并没有&lt;code&gt;config set dir&lt;/code&gt;的权限&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>