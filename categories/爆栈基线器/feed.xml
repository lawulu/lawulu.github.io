<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>璐濒殉漂流记</title>
    <link>https://lawulu.github.io/categories/%E7%88%86%E6%A0%88%E5%9F%BA%E7%BA%BF%E5%99%A8/feed/index.xml</link>
    <description>Recent content on 璐濒殉漂流记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <atom:link href="https://lawulu.github.io/categories/%E7%88%86%E6%A0%88%E5%9F%BA%E7%BA%BF%E5%99%A8/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Scrapy</title>
      <link>https://lawulu.github.io/post/Scrapy%E5%88%9D%E7%AA%A5/</link>
      <pubDate>Sat, 15 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Scrapy%E5%88%9D%E7%AA%A5/</guid>
      <description>

&lt;p&gt;先说结论，爬虫分为两种，一种是贪婪爬虫，最常用的就是搜索引擎，看见Url就爬。另外一种是专业爬虫，类似于网络小数定期更新，价格比对。Scrapy适合做第二种。Scrapy专心做爬取逻辑，其优势是框架比较成熟，各种插件比较全。如果真正做一个工业化的产品，Scrapy远远不够，还要攒很多东西进来。其实如果对&lt;code&gt;requests&lt;/code&gt;和&lt;code&gt;beautifulsoup&lt;/code&gt;熟悉，直接上这俩就挺好的。&lt;/p&gt;

&lt;h2 id=&#34;简介&#34;&gt;简介&lt;/h2&gt;

&lt;p&gt;Scrapy其实是一个很轻量级或者简单的框架。几个概念：
1. &lt;code&gt;Request&lt;/code&gt;,&lt;code&gt;Response&lt;/code&gt;，顾名思义，对应的就是网络的请求和响应。
2. &lt;code&gt;Item&lt;/code&gt;或者python dict,对应的是爬取到的结果。
3. &lt;code&gt;Pipeline&lt;/code&gt;对Item的处理。
4. &lt;code&gt;Selector&lt;/code&gt;对应的是对HTML的处理
5. &lt;code&gt;Middleware&lt;/code&gt;相当于Filter，分两种，一种是针对Spider，一种针对网络连接
6. &lt;code&gt;Scheduler&lt;/code&gt;一个深度优先的队列
7. &lt;code&gt;Feed&lt;/code&gt; 官方提供的json或者json line的输出
8. &lt;code&gt;meta&lt;/code&gt; 可以在多个Spider之间传输数据&lt;/p&gt;

&lt;p&gt;其实把文档看一遍，下一个demo，很快就可以跑起来。&lt;/p&gt;

&lt;p&gt;看图其实很清楚：
&lt;img src=&#34;https://lawulu.github.io/iimg/scrapy.png&#34; alt=&#34;Scrapy Arch&#34; /&gt;&lt;/p&gt;

&lt;p&gt;从StartRequest开始，不停的返回Item或者返回Request，如果返回Item，就发到Pipeline去处理，返回Request，经过Callback处理之后，直到所有的Request都变成Item。正所谓，世界是属于Request，归根结底还是属于Item的。&lt;/p&gt;

&lt;h2 id=&#34;简单示例&#34;&gt;简单示例&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;import scrapy
class ZhihuSpider(scrapy.Spider):
    name = &amp;quot;zhihu&amp;quot;
    start_urls = [
        &#39;https://www.zhihu.com/explore&#39;,
    ]

    def parse(self, response):
        # self.logger.info(&amp;quot;------zzhon中国&amp;quot;)

        for feed in response.css(&#39;.recommend-feed&#39;):
            link = response.urljoin(feed.css(&#39;a::attr(href)&#39;).extract_first());
            yield scrapy.Request(link,callback=self.parse_content)
           

##!!!  print response.css(&#39;#zh-question-detail &amp;gt; div&#39;).extract()[0].encode(&#39;utf-8&#39;)

    def parse_content(self,response):
        yield {
            &#39;title&#39;:response.css(&#39;#zh-question-title &amp;gt; h2 &amp;gt; a::text&#39;).extract_first(),
            &#39;content&#39;:response.css(&#39;#zh-question-detail &amp;gt; div::text&#39;).extract(),
            &#39;link&#39;:response.url
        }

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;当然这个示例跑起来之前，需要改一些配置文件和设置User-agent…&lt;/p&gt;

&lt;h2 id=&#34;吐槽&#34;&gt;吐槽&lt;/h2&gt;

&lt;h3 id=&#34;日志只打印unicode问题&#34;&gt;日志只打印Unicode问题&lt;/h3&gt;

&lt;p&gt;Debug和监控起来非常不方便，我看官方把这个issue当做wont fix了，强烈推荐直接上Python3。对非英文世界来说，Python2下scrapy shell简直没了存在的必要…&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2017-01-15 23:25:54 [scrapy] DEBUG: Scraped from &amp;lt;200 https://www.zhihu.com/question/29218955/answer/41797438&amp;gt; 
{&#39;content&#39;: [u&#39;\u666e\u6d31\u5728\u8fc7\u53bb\u5e94\u8be5\u662f\u4e0d\u4e0a\u53f0\u9762\u7684\u5427\uff1f\u4e5f\u6ca1\u95ee\u662f\u4e0d\u662f\u5c31\u95ee\u4e3a\u4ec0\u4e48\u4e86\uff0c\u5982\u679c\u95ee\u9898\u6709\u9519\u8bef\uff0c\u8bf7\u6307\u6b63&#39;], &#39;link&#39;: &#39;https://www.zhihu.com/question/19258955/answer/42797438&#39;, &#39;title&#39;: u&#39;\u666e\u6d31\u7531\u539f\u6765\u4e0d\u4e0a\u53f0\u9762\u7684\u8fb9\u9500\u8336\u5230\u5982\u4eca\u53d7\u5230\u5e7f\u5927\u8336\u53cb\u559c\u7231\u7684\u8336\u7c7b\uff0c\u9664\u4e86\u7092\u4f5c\u5916\uff0c\u666e\u6d31\u7684\u5de5\u827a\u6216\u8005\u8d28\u91cf\u6709\u4e86\u5f88\u5927\u8fdb\u6b65\u5417\uff1f&#39;} 

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scheduler太弱&#34;&gt;Scheduler太弱&lt;/h3&gt;

&lt;p&gt;自带的scheduler只能深度优先和广度优先，官方推荐是自家的scrapyd，稍微了解了下，应该是启动时候把任务分给多个进程，进程之间好像没法交互。&lt;/p&gt;

&lt;h3 id=&#34;spider-request之间很难协同&#34;&gt;Spider/Request之间很难协同&lt;/h3&gt;

&lt;p&gt;很多时候我们需要某几个Request应该在一个组里面，同一个组的Request可以共用Cookie，共用代理。这类的需求可以通过meta机制来实现…由于Scrapy的Request是无脑yield出来的，实现出来肯定很丑陋。&lt;/p&gt;

&lt;h3 id=&#34;callback-hell&#34;&gt;Callback hell&lt;/h3&gt;

&lt;p&gt;通过Callback来绑定处理方法，入口和可测试性很差，怪不得要加入Contract机制&lt;/p&gt;

&lt;h3 id=&#34;容错&#34;&gt;容错&lt;/h3&gt;

&lt;p&gt;容错机制很少，需要把Task持久化，官方提供的持久化到disk的方案感觉很初级很粗糙。&lt;/p&gt;

&lt;h2 id=&#34;splash&#34;&gt;Splash&lt;/h2&gt;

&lt;p&gt;Pyspider是用的&lt;code&gt;PhantomJS&lt;/code&gt;，Scrapy提供了一个基于Docker和Lua的Splash。
这货的问题是Splash没有保持渲染状态的方法，对于复杂的JS交互，一般的做法是一个lua脚本执行很多次，最后返回所有的结果。这样爬取的颗粒比较大，如果中间出现异常，不好处理，而且调用&lt;code&gt;splash::wait()&lt;/code&gt;总感觉不靠谱，没有提供Dom加载之后的回调吗？&lt;/p&gt;

&lt;h3 id=&#34;原理&#34;&gt;原理&lt;/h3&gt;

&lt;p&gt;Splash可以执行Lua脚本，官方封装了Splash类，可以和JS交互。这样，就可可以找到Dom中的Button，直接调用click事件，然后返回某些DOM中的Html或者Json。&lt;/p&gt;

&lt;h3 id=&#34;lua&#34;&gt;Lua&lt;/h3&gt;

&lt;p&gt;Lua 很值得一学，Nginx，游戏引擎，Redis都在用……
快速入门：&lt;a href=&#34;http://tylerneylon.com/a/learn-lua/&#34;&gt;http://tylerneylon.com/a/learn-lua/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Lua稍微复杂并且可以玩出花的内置机制就是Metatable了，可以重载对字典(对象)各种操作符。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>一次Ajax上传文件的调试过程</title>
      <link>https://lawulu.github.io/post/%E4%B8%80%E6%AC%A1Ajax%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E7%9A%84%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B/</link>
      <pubDate>Sat, 19 Dec 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E4%B8%80%E6%AC%A1Ajax%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E7%9A%84%E8%B0%83%E8%AF%95%E8%BF%87%E7%A8%8B/</guid>
      <description>

&lt;p&gt;很久不做Web了，帮一小弟解决的一个问题。据他说无脑搜了很久…&lt;/p&gt;

&lt;h2 id=&#34;现象和代码&#34;&gt;现象和代码&lt;/h2&gt;

&lt;h3 id=&#34;js端&#34;&gt;Js端&lt;/h3&gt;

&lt;p&gt;使用的FormData&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var formData = new FormData();
    var actionUrl = &amp;quot;/report/agentUpload&amp;quot;;
    var form = new FormData();
    form.append(&amp;quot;file&amp;quot;, $(&amp;quot;#reportFile&amp;quot; )[0]);

    var xhr = new XMLHttpRequest();
    xhr.open(&amp;quot;post&amp;quot;, actionUrl, true);
    xhr.onload = function () {
         alert(&amp;quot;上传完成!&amp;quot;);
    };

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;server端&#34;&gt;Server端&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;public String upload(HttpServletRequest request, @RequestParam(value=&amp;quot;file&amp;quot;,required = true) MultipartFile file, ModelMap model)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;但是就是取不到，报错：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Required MultipartFile parameter &#39;file&#39; is not present
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;server端的问题&#34;&gt;Server端的问题？&lt;/h2&gt;

&lt;p&gt;是否发到了Server？&lt;/p&gt;

&lt;p&gt;看Chrome Network面板里面这次请求的Request：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;------WebKitFormBoundaryNLPhxKE21THaBaN1
Content-Disposition: form-data; name=&amp;quot;file&amp;quot;

[object HTMLInputElement]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;貌似是正确的，在Server端确认一下，将参数加上required=false
查看request:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;multipartParameters = {HashMap@8882}  size = 1
multipartParameterContentTypes = {HashMap@8883}  size = 1
multipartFiles = {LinkedMultiValueMap@8884}  size = 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Request里面有东西，但是multipartFiles没有东西……&lt;/p&gt;

&lt;p&gt;&lt;em&gt;其实这时候应该已经看出问题了，因为那个值是一个String，但是没注意，自己盲目以为只要带multipartParameters就是文件&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;debug到CommonsMultipartResolver的resolveMultipart方法，里面有这段判断&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;protected MultipartParsingResult parseFileItems(List&amp;lt;FileItem&amp;gt; fileItems, String encoding) {
		MultiValueMap&amp;lt;String, MultipartFile&amp;gt; multipartFiles = new LinkedMultiValueMap&amp;lt;String, MultipartFile&amp;gt;();
		Map&amp;lt;String, String[]&amp;gt; multipartParameters = new HashMap&amp;lt;String, String[]&amp;gt;();
		Map&amp;lt;String, String&amp;gt; multipartParameterContentTypes = new HashMap&amp;lt;String, String&amp;gt;();

		// Extract multipart files and multipart parameters.
		for (FileItem fileItem : fileItems) {
			if (fileItem.isFormField()) {
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;如果是false…就往MultipartFile里面填值。
难道是Content-type的问题？&lt;/p&gt;

&lt;h3 id=&#34;去js端&#34;&gt;去Js端&lt;/h3&gt;

&lt;p&gt;先找到如何打印Formdata的：
&lt;a href=&#34;http://stackoverflow.com/questions/17066875/how-to-inspect-formdata&#34;&gt;http://stackoverflow.com/questions/17066875/how-to-inspect-formdata&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (var pair of formData.entries()) {
    console.log(pair[0]+ &#39;, &#39; + pair[1]); 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;打印的东西是：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;file, [object HTMLInputElement]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;决定采用原始的document.getElementById(&amp;ldquo;reportFile&amp;rdquo;).files[]&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;lastModifiedDate: Tue Dec 20 2015 10:39:39 GMT+0800 (CST)name: &amp;quot;工作簿1.xlsx&amp;quot;size: 23168type: &amp;quot;application/vnd.openxmlformats-officedocument.spreadsheetml.sheet&amp;quot;webkitRelativePath: &amp;quot;&amp;quot;__proto__: File

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;最终发现问题：
应该用&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; $(&amp;quot;#reportFile&amp;quot; )[0].files[0]

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;结论&#34;&gt;结论&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;盲目的去搜索其实非常浪费时间&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;要善用Chrome Console&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>一个诡异的Data source is closed问题</title>
      <link>https://lawulu.github.io/post/%E4%B8%80%E4%B8%AA%E8%AF%A1%E5%BC%82%E7%9A%84Data%20source%20is%20closed%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 19 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E4%B8%80%E4%B8%AA%E8%AF%A1%E5%BC%82%E7%9A%84Data%20source%20is%20closed%E9%97%AE%E9%A2%98/</guid>
      <description>

&lt;h3 id=&#34;问题由起&#34;&gt;问题由起&lt;/h3&gt;

&lt;p&gt;因为某些问题（这个问题稍后再提），将线上的DBCP版本从1.4升级到2.1，大概扫了一下官方文档，没有迁移指南，只是几个属性名称变了，感觉问题不大，直接升级。升级之后，UT一下，通过。但是上线之后一直报下面错误：
&amp;gt;Cause: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Data source is closed
    at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:23)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:107)
    at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:98)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:386)
    &amp;hellip; 43 more&lt;/p&gt;

&lt;h3 id=&#34;问题背景&#34;&gt;问题背景&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;项目因为需要动态切换数据源，使用的是++AbstractRoutingDataSource++&lt;/li&gt;

&lt;li&gt;&lt;p&gt;需要动态切换的数据源比较多，项目初始化时候通过++BeanDefinitionBuilder++来根据数据库配置动态创建数据源，而报错的连接正是动态生成的的数据源。&lt;/p&gt;

&lt;h3 id=&#34;问题定位&#34;&gt;问题定位&lt;/h3&gt;

&lt;h4 id=&#34;为什么ut测试成功&#34;&gt;为什么UT测试成功&lt;/h4&gt;

&lt;p&gt;原来是UT的时候，因为配置文件，测试其实走的是++AbstractRoutingDataSource++的默认的数据源，并没有走动态生成的数据源&lt;/p&gt;

&lt;h4 id=&#34;怀疑是参数问题或者其他原因&#34;&gt;怀疑是参数问题或者其他原因&lt;/h4&gt;

&lt;p&gt;只设置JDBC Url，依旧报错；换成dbcp，不报错。&lt;/p&gt;

&lt;h4 id=&#34;abstractroutingdatasource的问题&#34;&gt;AbstractRoutingDataSource的问题？&lt;/h4&gt;

&lt;p&gt;使用XML配置，没有问题&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;至此，基本确认是++DBCP2++和++BeanDefinitionBuilder++&lt;/strong&gt;的问题&lt;/p&gt;

&lt;h3 id=&#34;查看源码和debug&#34;&gt;查看源码和Debug&lt;/h3&gt;

&lt;h4 id=&#34;basicdatasource-dbcp1和2有什么区别&#34;&gt;BasicDataSource DBCP1和2有什么区别？&lt;/h4&gt;

&lt;p&gt;DBCP2实现了更多的接口：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class BasicDataSource implements DataSource, BasicDataSourceMXBean, MBeanRegistration, AutoCloseable 

&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;查看dbcp2创建链接和销毁的地方&#34;&gt;查看DBCP2创建链接和销毁的地方&lt;/h4&gt;

&lt;p&gt;是没有Create Connection还是什么时候被Close了？
被Close了&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
		this.beanDefinitionMap.put(beanName, beanDefinition);

		if (oldBeanDefinition != null || containsSingleton(beanName)) {
			resetBeanDefinition(beanName);
		}
		
		
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;protected void resetBeanDefinition(String beanName) {
		// Remove the merged bean definition for the given bean, if already created.
		clearMergedBeanDefinition(beanName);

		// Remove corresponding bean from singleton cache, if any. Shouldn&#39;t usually
		// be necessary, rather just meant for overriding a context&#39;s default beans
		// (e.g. the default StaticMessageSource in a StaticApplicationContext).
		destroySingleton(beanName);

		// Reset all bean definitions that have the given bean as parent (recursively).
		for (String bdName : this.beanDefinitionNames) {
			if (!beanName.equals(bdName)) {
				BeanDefinition bd = this.beanDefinitionMap.get(bdName);
				if (beanName.equals(bd.getParentName())) {
					resetBeanDefinition(bdName);
				}
			}
		}
	}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;原来Spring创建Bean的时候会检查是否有oldBeanDefinition,如果有则销毁之。而DBCP2实现了AutoCloseable接口，在这里直接被Close了。&lt;/p&gt;

&lt;h4 id=&#34;为什么有oldbeandefinition&#34;&gt;为什么有oldBeanDefinition？&lt;/h4&gt;

&lt;p&gt;为了支持另一种类型的数据源，引入了一个Bug，会在Spring BeanFactory里面引入重复的定义，因为在AbstractRoutingDataSource中是正确的，所以一直没有发现这个问题。第二次会销毁上次的Bean。
其实在DBCP1时候，也会销毁，但是因为在动态定义的时候没有定义destroy-method=&amp;ldquo;close&amp;rdquo;，其实会引起内存的泄露？&lt;/p&gt;

&lt;p&gt;结论：很多看似运行完好的软件其实都危机四伏..&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Logback的一些奇技淫巧</title>
      <link>https://lawulu.github.io/post/Logback%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/</link>
      <pubDate>Sun, 23 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Logback%E7%9A%84%E4%B8%80%E4%BA%9B%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/</guid>
      <description>

&lt;p&gt;Logback是一款非常优秀的日志框架。但是每个开发面对的需求也是多种多样的。
如果你有下面的需求，那你看了这篇文章就可以了：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;每次调用链都生成一个唯一的traceId&lt;/li&gt;
&lt;li&gt;修改配置文件即时生效，例如，为了定位一个问题，临时将log级别修改为debug&lt;/li&gt;
&lt;li&gt;不同环境使用不同的配置&lt;/li&gt;
&lt;li&gt;Logback的默认Rolling策略是：有新的Log产生，如果需要rolling，则rename原来的文件。这样会存在的一个问题就是，如果没有新的log产生，就不会重命名原来的文件。如果遇上需要同步日志（例如Rsync），就会出现问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;日志的traceid&#34;&gt;日志的TraceId&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;在Filter里面增加一个，ThreadLocal based 变量：&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;
public class CustomFilter extends OncePerRequestFilter {
	
	private static final Random random = new Random(System.currentTimeMillis()); //TODO

	@Override
	protected void doFilterInternal(HttpServletRequest request,
			HttpServletResponse response, FilterChain filterChain)
			throws ServletException, IOException {
		
	
		request.setAttribute(ApiConstants.RQID, rnd);
		
		response.setHeader(ApiConstants.HEADER_RQID, rnd);
		MDC.put(ApiConstants.RQID, rnd);
		try{
			filterChain.doFilter(request, response);
		}finally{
			MDC.remove(ApiConstants.RQID);
		}

	}

}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;配置文件&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt; &amp;lt;encoder&amp;gt;
	        &amp;lt;pattern&amp;gt;%d{yyyy-MM-dd HH:mm:ss} %-4relative [%thread] %-5level %logger{35} [%X{x-jjk-rqid:-notFound}]- %msg%n&amp;lt;/pattern&amp;gt;
	    &amp;lt;/encoder&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;自动更新配置&#34;&gt;自动更新配置&lt;/h3&gt;

&lt;p&gt;显然会影响效率&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;configuration debug=&amp;quot;true&amp;quot; scan=&amp;quot;true&amp;quot; scanPeriod=&amp;quot;1 minutes&amp;quot;&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;各个环境引入不同的profile&#34;&gt;各个环境引入不同的Profile&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;	&amp;lt;property resource=&amp;quot;config/config-${envTarget}.properties&amp;quot;/&amp;gt;

&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;基于条件写不同的文件-siftingappender&#34;&gt;基于条件写不同的文件：SiftingAppender&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt; &amp;lt;appender name=&amp;quot;stats&amp;quot; class=&amp;quot;ch.qos.logback.classic.sift.SiftingAppender&amp;quot;&amp;gt;
        &amp;lt;!-- in the absence of the class attribute, it is assumed that the
             desired discriminator type is
             ch.qos.logback.classic.sift.MDCBasedDiscriminator --&amp;gt;
        &amp;lt;discriminator&amp;gt;
            &amp;lt;key&amp;gt;date&amp;lt;/key&amp;gt;
            &amp;lt;defaultValue&amp;gt;unknown&amp;lt;/defaultValue&amp;gt;
        &amp;lt;/discriminator&amp;gt;
        &amp;lt;sift&amp;gt;
            &amp;lt;appender name=&amp;quot;FILE-${date}&amp;quot; class=&amp;quot;ch.qos.logback.core.FileAppender&amp;quot;&amp;gt;
                &amp;lt;file&amp;gt;/mnt/media-${date}.log&amp;lt;/file&amp;gt;
                &amp;lt;!--&amp;lt;append&amp;gt;false&amp;lt;/append&amp;gt;--&amp;gt;
                &amp;lt;encoder&amp;gt;
                    &amp;lt;pattern&amp;gt;%msg%n&amp;lt;/pattern&amp;gt;
                    &amp;lt;charset&amp;gt;UTF-8&amp;lt;/charset&amp;gt;
                &amp;lt;/encoder&amp;gt;
            &amp;lt;/appender&amp;gt;
        &amp;lt;/sift&amp;gt;
    &amp;lt;/appender&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;代码中需要写MDC变量：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        MDC.put(&amp;quot;date&amp;quot;, dateString);

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>一种统一的API签名校验实现</title>
      <link>https://lawulu.github.io/post/%E4%B8%80%E7%A7%8D%E7%BB%9F%E4%B8%80%E7%9A%84API%E7%AD%BE%E5%90%8D%E6%A0%A1%E9%AA%8C%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 10 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E4%B8%80%E7%A7%8D%E7%BB%9F%E4%B8%80%E7%9A%84API%E7%AD%BE%E5%90%8D%E6%A0%A1%E9%AA%8C%E6%96%B9%E6%B3%95/</guid>
      <description>

&lt;h2 id=&#34;签名方法&#34;&gt;签名方法:&lt;/h2&gt;

&lt;h2 id=&#34;header&#34;&gt;Header:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;
@RequestHeader(value = &amp;quot;x-header-timestamp&amp;quot;) Long timestamp,
@RequestHeader(value = &amp;quot;x-header-appid&amp;quot;) String appid,
@RequestHeader(value = &amp;quot;x-header-sign&amp;quot;) String sign
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;源串-orignalstring&#34;&gt;源串 orignalString:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;
HttpMethod=URI&amp;amp;Param1=Value1&amp;amp;Param2=Value2RequestBodySeckeyTimestamp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;注1:Method大写
注2:为方便期间Param不排序,如果出问题再说
注3:ResustBody可能为空
注4:SecKey跟AppId是一一对应.&lt;/p&gt;

&lt;h2 id=&#34;签名-sign&#34;&gt;签名 sign:&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sign=Md5(orignalString).toUpperCase
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;暂时只支持MD5&lt;/p&gt;

&lt;h2 id=&#34;实现&#34;&gt;实现:&lt;/h2&gt;

&lt;p&gt;原则上,应该和业务逻辑代码分离,不影响业务逻辑代码的开发&lt;/p&gt;

&lt;h3 id=&#34;1-根据注解mapping需要检查签名的方法&#34;&gt;1 根据注解Mapping需要检查签名的方法&lt;/h3&gt;

&lt;p&gt;例如:Spring @ControllerAdvice(annotations = RestController.class)
如需要,可自定义自己的注解&lt;/p&gt;

&lt;h3 id=&#34;2-获取参数&#34;&gt;2 获取参数&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;
@ModelAttribute
	public void checkSign(HttpServletRequest request, HttpServletResponse response, @RequestBody(required=false) String requestbody,
			@RequestHeader(value = &amp;quot;x-header-timestamp&amp;quot;) Long timestamp,
			@RequestHeader(value = &amp;quot;x-header-appid&amp;quot;) String appid,
			@RequestHeader(value = &amp;quot;x-header-sign&amp;quot;) String sign) 
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-计算签名&#34;&gt;3 计算签名&lt;/h3&gt;

&lt;p&gt;可能需要在GLobalExceptionHandler中增加&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
    @ExceptionHandler(ServletRequestBindingException.class) 
    	@ResponseStatus(HttpStatus.BAD_REQUEST)	
    	@ResponseBody 
    	ErrorMessage handleServletRequestBindingException(ServletRequestBindingException ex) {	
    		
    		LOGGER.debug(&amp;quot;handleServletRequestBindingException&amp;quot;, ex);
    		return new ErrorMessage(ErrorCode.INVALID_HEADER.getCode(), ex.getMessage());//TODO
    	}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;增加filter&#34;&gt;增加Filter&lt;/h2&gt;

&lt;p&gt;注意：因为在ControllerAdvice消费了Request的InputStream，所以需要在前面的Filter中Copy一份Request出来
代码如下：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/**
 * Wrapper used to be able to consume multiple times the InputStream provided by
 * HttpServletRequest
 *
 * @author lawulu
 * @see https://github.com/ClouDesire/spring-utils/
 * 
 */

public class CustomHttpServletRequestWrapper extends HttpServletRequestWrapper {
    private final byte[] body;

    public CustomHttpServletRequestWrapper(HttpServletRequest request) throws IOException {
        super(request);
        if (request.getContentType() != null
                &amp;amp;&amp;amp; request.getContentType().contains(MediaType.APPLICATION_JSON.toString())) {
            InputStream inputStream = request.getInputStream();
            if (inputStream != null) {
                body = IOUtils.toByteArray(inputStream);
                return;
            }
        }
        body = null;
    }

    @Override
    public ServletInputStream getInputStream() throws IOException {
        if (body == null)
            return super.getInputStream();

        final ByteArrayInputStream stream = new ByteArrayInputStream(body);
        ServletInputStream inputStream = new ServletInputStream() {
            @Override
            public int read() throws IOException {
                return stream.read();
            }
        };
        return inputStream;
    }

    @Override
    public BufferedReader getReader() throws IOException {
        if (body == null)
            return super.getReader();

        return new BufferedReader(new InputStreamReader(new ByteArrayInputStream(body), StandardCharsets.UTF_8));
    }

}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>