<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>璐濒殉漂流记</title>
    <link>https://lawulu.github.io/tags/spark/feed/index.xml</link>
    <description>Recent content on 璐濒殉漂流记</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <atom:link href="https://lawulu.github.io/tags/spark/feed/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>小陈与大数据的故事</title>
      <link>https://lawulu.github.io/post/%E5%B0%8F%E9%99%88%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%85%E4%BA%8B/</link>
      <pubDate>Fri, 15 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/%E5%B0%8F%E9%99%88%E4%B8%8E%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%9A%84%E6%95%85%E4%BA%8B/</guid>
      <description>

&lt;p&gt;&lt;em&gt;本篇为公众号&lt;code&gt;码农翻身&lt;/code&gt;的约稿，最终想写4篇，分别为&lt;code&gt;陈余罗严&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;在学校&#34;&gt;在学校&lt;/h2&gt;

&lt;p&gt;做为一个科班出身的程序员，在小陈还不明白自己所学的的数据结构和操作系统这些专业课跟未来的工作有什么关系，甚至未来做什么也不清楚时候，小陈最喜欢做的事就是看电影，看完还舍不得删。那个时代流行的还是“为人不识武藤兰，阅遍电影也枉然”，电影还有很多是rm格式的，几百兆都算大的，但是架不住小陈对一衣带水邻国文化的热爱，只有120G的硬盘让他很快有了另一个爱好：整理硬盘，每次有新资源出来，小陈都得想办法腾点空间出来。&lt;/p&gt;

&lt;p&gt;后来教育网里一个叫Maze的软件在学校流行开来，这个软件可以在局域网内以P2P的方式完成资源共享。喜大普奔，小陈得意洋洋的宣布自己终于不用整理硬盘了，自己硬盘里面只存一部分经典的，想看什么电影从别人机器里面拖，哪怕自己临时要看一个美帝大片，删掉一部分电影，删掉之后都还能从别人机器里面拖回来。&lt;/p&gt;

&lt;p&gt;直到有一天，小陈临时删了一位老师的代表作，等想找回来时候，不知道是学校调整了网络路由还是因为高年级学生的离校，这部本来在Maze中非常常见的电影居然一个都找不到了。小陈被室友嘲笑之余，怒而卸载了Maze，并决定要开发一套更好的共享资源软件：要有一个元数据服务器，所有使用者的硬盘的读写都由元数据服务器来管理，元数据保证每份电影都至少存在2份以上，而不是像现在这样保存什么电影，全靠用户心照不宣的默契和自己的兴趣。&lt;/p&gt;

&lt;p&gt;不过小陈也面临着毕业，自然没有时间去搞这些乱七八糟的东西，为了找工作，开始恶补各种技能。这已经是2011年，大数据已经开始火起来了，小陈开始试着学习大数据的知识。搞Android培训的那波人摇身一变开始培训Hadoop了，小陈上了一次试听课之后，回来开始向室友生成，自己的创意被Google和Hadoop给剽窃了！大数据首先要解决的都是存储问问题，GFS，以及受之启发的Hadoop HDFS，完全就是照着自己的资源共享软件思路来的。&lt;/p&gt;

&lt;p&gt;其实小陈知道，Google在2003年就把GFS的论文给写出来，开发这个GFS时候武老师可能还没有出道，甚至BigData这个词还没有被清楚的定义。但是Google作为技术最领先，体量最大的搜索引擎公司，很早就面临和自己类似的问题:大量的数据(信息索引和网页快照等等)要怎么存储存储在哪里的问题。Google选择的是用大量的通用硬件组成一个可以横向扩展的集群去对存储和处理这些海量的数据。这种英雄所见略同的感觉，让小陈决定要从事大数据开发，毕竟这个越来越自我的世界，随着移动互联网的爆发，每个人制造的垃圾数据会越来越容易，而制造垃圾数据的人也会越来越多。&lt;/p&gt;

&lt;h2 id=&#34;第一份工作&#34;&gt;第一份工作&lt;/h2&gt;

&lt;p&gt;找大数据的工作并不顺利，心仪的公司嫌自己没有经验，给Offer的公司貌似没有多少数据，只是想趁着大数据热忽悠一把。阴错阳差，小陈找到一份Java开发的工作。这家公司专做某行业的软件，公司不大但发展很快，待遇还算不错。小陈第一周上班主要学习公司的技术框架，然后就懵逼了。面试时候非要分清POBOVO，现在项目所有的参数传递都是List&lt;Map&gt;；面试时候各种设计模式的问，结果这项目的大部分的业务逻辑都是写在SQL存储过程里面的，甚至JS里面也夹杂了很多SQL；自研的一个工作流框架对应的库表，各种预留字段，从field1，field2一直到field8。在小陈犹豫着要不要换家公司，技术总监的几句话给忽悠住了他：这个世界的所有事物，即所谓的对象，都是可以用List&lt;Map&gt;来表示；SQL是史上的最好的DSL，一定要充分利用，如果想写，用SQL实现一个Dijkstra算法都可以[注1]；这框架虽然不走寻常路，但是有PHP的开发速度，也利用JVM的性能和Java的生态系统。&lt;/p&gt;

&lt;p&gt;小陈不仅觉得总监的话很有道理，而且这些话跟大数据的思路也有几份相似。Google开启大数据时代最重要的就是三篇论文:Google File System,讲如何分布式存储大数据；Google MapReduce,讲如何分布式计算大数据；Google Bigtable,实现了一个数据库，以便在分布式下快速读写结构化数据。对应的开源实现是Hadoop Hdfs，Hadoop MapReduce，HBase。这个识万物为List&lt;Map&gt;的思路不就是MapReduce的思路吗，而那个预留字段的数据库设计其实有点Bigtable/HBase的风范，不管神似与否至少形似。工作一段时间，小陈感觉这糙快猛的框架确实还是很适合这个需求变化比较快的行业，对他自己来说，至少写SQL和实现业务需求的能力提高了不少。一年之后，小陈跳槽到一家三线互联网公司做大数据，凭借的就是这两项能力。&lt;/p&gt;

&lt;h2 id=&#34;大数据工作和两个领导&#34;&gt;大数据工作和两个领导&lt;/h2&gt;

&lt;p&gt;新公司工作主要基于Shell调用Hive，把数据从日志往Oracle里面导，经常还要给业务部门提数。所以，虽然在做大数据，工作内容只是从上家公司的Oracle PL/SQL换成了Hive SQL。Map-Reduce虽然直指大数据计算的本源，但是奈何这个世界太复杂，产品经理的需求太多，表达力有点欠缺。而且又很多通用的需求，例如数据之间的Join和Group，完全可以提炼出来，于是Facebook向开源社区捐献了Hive，用史上的最好的DSL作为查询语言交给熟悉SQL的人去使用，Hive引擎负责把SQL翻译成MapReduce。小陈得偿所愿进入大数据行业，但是很快就厌倦了：Shell管理起来太麻烦，跟其他系统交互起来不方便；Hive运行太慢，资源利用率低，有时候跑了十几分钟结果出来了发现自己的SQL有一个简单的错误；想推动HadoopV2的落地，让Yarn去合理的管理集群资源，领导和同事都不愿意承担风险。小陈隐约觉得自己做的东西并没有给公司带来应有的价值，只是让报表的维度增加一些。领导告诉小陈，大数据并不是解决一切问题的灵丹妙药，数据越来越多，增加更多的是无价值的数据，而大数据处理的日志等数据与业务数据相比，信息熵要低的多。&lt;/p&gt;

&lt;p&gt;就这么工作一年后，老板也对数据部门不满意，赶走了老领导，挖来一个大厂的架构师来主管整合所有数据相关业务。新领导上来就大刀阔斧，部门架构调整，把一部分数据相关的开发并了过来，整个部门一分为二，一部分往上跟业务和产品部门打交道，一部分下沉做大数据平台时候。小陈果断的选择了去做平台。&lt;/p&gt;

&lt;p&gt;如果说老领导强调的是数据完整性和正确性，数据对业务的支撑，新领导更强调数据对产品和决策的反馈，技术的先进性。按照新领导的意思，以做用户数据仓库为出发点，从数据收集、数据转换、数据模型、数据查询、数据可视化到任务调度和平台监控，要重新梳理现有每一个模块的技术架构。这个时候，大数据相关技术已经可以说是百花齐放百家争鸣，围绕着Hadoop，几乎每个领域都有一两个出色的解决方案。领导要求使用技术要向代表技术先进性，相关软件版本落后不能超过2年，鼓励使用3年以内的新项目。小陈很高兴，感觉可以大干一场了。因为态度积极，小陈很受新领导的器重，小陈先负责用其他SQL on Hadoop的如Impala/Presto来代替Hive的部分功能，提高查询效率，后来又负责引入实时计算框架Storm，虽然只是用来计算PV/UV，但好歹是实时的。总之是趟坑无数，背锅无数，忙得不亦乐乎。&lt;/p&gt;

&lt;p&gt;直到又过一年公司裁员，小陈才发现数据部门是重灾区。和领导吃散伙饭，小陈开始鸣不平，觉得咱们的平台做了这么多，大家加班这么辛苦，为什么就没人懂欣赏呢。领导却直言自己早就知道这个结局，部门折腾了一年，老板只看到数据部门人员和机器一直在增加，却经常收到其他部门各种抱怨，产品抱怨进度太慢啊，商务说数据不懂业务啊，研发说总是要配合数据做这做那啊，运营说报表没有老系统方便数据老出问题等等。相处这么久，领导已经把小陈当心腹了，直言一开始想把有些业务拿到数据这边统一处理，技术出身搞不定公司复杂的关系，阻力太大；埋头把平台理顺，而在强势老板的公司里面，自己还是没有抓住老板的需求和业务的痛点，所以对老板来说，确实没为公司带来什么价值。领导的这番肺腑之言对小陈触动很大，开始重新审视自己的过去的工作。不管怎样小陈这时候找下一份工作已经有了一份资本。&lt;/p&gt;

&lt;h2 id=&#34;在创业公司&#34;&gt;在创业公司&lt;/h2&gt;

&lt;p&gt;在全民创业的浪潮中，小陈来到一家创业公司，这里还没有什么&amp;rdquo;大数据&amp;rdquo;,但是CEO的数据要介入整个产品和运营中的承诺和希望打动了小陈，而且这里有机会从零开始有机会按照自己的思路规划整个公司的大数据业务。这个时候，大数据圈最火的是Spark，Spark以基于内存的DAG计算引擎为基础，提供了批量计算，实时计算，交互式查询，机器学习，基本上实现了One Stack To Rule Them All，而且Spark也有SparkSQL。小陈选择了围绕Spark来构建整个系统，并且拥抱云计算了，直接选择云服务，希望自己能专注于让数据产生价值。小陈工作分这么几部分:输出报表数据;给一个数据科学家打杂，帮他整理数据提取特征，实现一些算法;每天花一个小时看数据，解释数据和用数据去解释。小陈成了对公司业务和系统最了解的人，比产品和QA都要了解，并且提出了很多优化和改进。CEO很满意，年终时候大笔一挥给了更多的期权，然而没什么卵用，因为融资寒冬来的时候，公司还是倒了。&lt;/p&gt;

&lt;h2 id=&#34;在大厂&#34;&gt;在大厂&lt;/h2&gt;

&lt;p&gt;小陈已经拖家带口了，感觉自己不再年轻，在机构Offer之间犹豫了很久之后，选择了去一个大厂做螺丝钉，这里流程和工具都已经非常完善了，用的Hadoop都是自己定制甚至已经跟社区不兼容了。小陈业务时间乐于参加各种线下各种活动，积攒自己的人脉，坚持更新Blog，提升自己的名气。&lt;/p&gt;

&lt;p&gt;这个时候Google推出了Beam计算框架。其实Google抛出了三大论文之后，表面上很沉寂，自己内部的系统却一直在向前演进，例如老版的GFS已经被Colossus被代替。直到Google眼红AWS投身云计算时候，发现客户都更习惯开源的那套东西，甚至Google把自己的BigTable服务往外卖的时候，不得不兼容BigTable的山寨产品HBase的API。这就好比一个欧洲人找到一个中国建筑师建一个亚洲古代建筑，中国建筑师给建了一个唐朝风格的建筑，欧洲人说，你这建的不大对，我在日本看到的都是这样那样。Google为了争夺话语权，把自己最新的产品拿出来开源，要一统所有的计算框架，不管你底层是Storm还是Spark，按照Beam的API来处理数据，底层可以随意切换Spark和自家的Cloud Dataflow，甚至为了师出有因，大力提携Flink和Spark打擂台。小陈相信这个框架会一统江湖，为了自己的KPI和升级, 准备在公司推Apache Beam。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transform技术选型：Spark Structured Streaming Vs Pure Scala</title>
      <link>https://lawulu.github.io/post/Transform%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%EF%BC%9ASpark%20Vs%20Scala/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Transform%E6%8A%80%E6%9C%AF%E9%80%89%E5%9E%8B%EF%BC%9ASpark%20Vs%20Scala/</guid>
      <description>

&lt;h2 id=&#34;需求&#34;&gt;需求&lt;/h2&gt;

&lt;p&gt;公司要上实时，需要一个应用对原始日志进行转换，简单来说：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;从Kafka读取数据，然后写回到Kafka&lt;/li&gt;
&lt;li&gt;对日志和数据进行合并&lt;/li&gt;
&lt;li&gt;完成归因、去重、真实点击等其他需求&lt;/li&gt;
&lt;li&gt;完成计费&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;有这么几个技术需求：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Json的处理，FileBeat产生的In和Druid需要的Out都是Json形式。&lt;/li&gt;
&lt;li&gt;Kafka读写&lt;/li&gt;
&lt;li&gt;外部数据源，Mysql，Redis和MongoDB的读取&lt;/li&gt;
&lt;li&gt;逻辑处理&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;spark-or-scala&#34;&gt;Spark or Scala&lt;/h2&gt;

&lt;p&gt;所谓的Spark，即Spark Structured Streaming，所谓的Scala是Scala based on Play Framework
优先考虑的是Spark（Spark Structured Streaming），因为Spark可以做流处理和即席查询，某种程度上可以复用很多逻辑，并且可以接入Hive-serde表，与无缝与Hive切换。&lt;/p&gt;

&lt;h3 id=&#34;技术需求&#34;&gt;技术需求&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Json

&lt;ul&gt;
&lt;li&gt;Spark：问题不大，但需要调研，Scala貌似没什么好用的Json库&lt;/li&gt;
&lt;li&gt;Scala：Play自带Json库&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Kafka

&lt;ul&gt;
&lt;li&gt;Spark：官方提供有类库，但是屏蔽的细节太多了。现在项目内没人清楚DStream/Spark.readStream是怎么个机制&lt;/li&gt;
&lt;li&gt;Scala：Kafka官方的Client是Java的，Akka Stream有对应的封装。如果不能用，解决起来也比较方便&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;外部DB

&lt;ul&gt;
&lt;li&gt;Spark：问题不大，需要调研如果精细的控制Partiton与连接之间的关系，还有Lookup问题&lt;/li&gt;
&lt;li&gt;Scala：Scala有各种Reactive的驱动&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;非技术需求&#34;&gt;非技术需求&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;监控&amp;amp;日志

&lt;ul&gt;
&lt;li&gt;用Spark的话，现有公司/阿里云的各种基础设施很难用的上&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;补数，关键是对Kafka的Offset做精细的控制

&lt;ul&gt;
&lt;li&gt;搜了一下，Spark这块放到Checkpoint了&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;TroubleShooting

&lt;ul&gt;
&lt;li&gt;Spark：？？？公司现在并没有用Spark跑大规模的应用&lt;/li&gt;
&lt;li&gt;Scala：Akka这块&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;

&lt;p&gt;所谓Spark的优势：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;以RDD/DataFrame/SQL形式提供的对数据处理的DSL，虽然比Hive效率更高，可以和Scala程序同时工作&lt;/li&gt;
&lt;li&gt;横向扩展以及容错&lt;/li&gt;
&lt;li&gt;Broadcast/Accumulator等原语&lt;/li&gt;
&lt;li&gt;可以有效利用HDFS对应的计算资源，并且做为一个Unified的平台，理论上可以重用很多逻辑&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Spark的问题：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Structured Streaming API 不稳定，我自己测试发现有Job莫名奇妙不运行的情况。&lt;/li&gt;
&lt;li&gt;任务调度和执行都是黑盒&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Spark并不是银弹，更倾向于用纯Java应用来做。Spark的优势在一个纯Transform的应用里面发挥不出来（上面三点：1显然不如直接写程序，对于2瓶颈在Kafka，3引入Redis可以解决类似问题。
）。后续可以研究一下Kafka Streams。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SparkML-卡方检验</title>
      <link>https://lawulu.github.io/post/SparkML-%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C/</link>
      <pubDate>Tue, 18 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/SparkML-%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C/</guid>
      <description>

&lt;h2 id=&#34;spark例子&#34;&gt;Spark例子&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;//org.apache.spark.examples.ml.ChiSquareTestExample

val data = Seq(
      (0.0, Vectors.dense(0.5, 10.0)),
      (0.0, Vectors.dense(1.5, 20.0)),
      (1.0, Vectors.dense(1.5, 30.0)),
      (0.0, Vectors.dense(3.5, 30.0)),
      (0.0, Vectors.dense(3.5, 40.0)),
      (1.0, Vectors.dense(3.5, 40.0))
    )

val df = data.toDF(&amp;quot;label&amp;quot;, &amp;quot;features&amp;quot;)
val chi = ChiSquareTest.test(df, &amp;quot;features&amp;quot;, &amp;quot;label&amp;quot;).head
println(&amp;quot;pValues = &amp;quot; + chi.getAs[Vector](0))
println(&amp;quot;degreesOfFreedom = &amp;quot; + chi.getSeq[Int](1).mkString(&amp;quot;[&amp;quot;, &amp;quot;,&amp;quot;, &amp;quot;]&amp;quot;))
println(&amp;quot;statistics = &amp;quot; + chi.getAs[Vector](2))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chi: org.apache.spark.sql.Row = [[0.6872892787909721,0.6822703303362126],WrappedArray(2, 3),[0.75,1.5]]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;因为Vector是两列，所以结果也是两列，即，需要检测每一个维度和label相关性。&lt;/p&gt;

&lt;h2 id=&#34;几个概念&#34;&gt;几个概念&lt;/h2&gt;

&lt;h3 id=&#34;卡方检验&#34;&gt;卡方检验&lt;/h3&gt;

&lt;p&gt;卡方检验两个用途：
- 检测一批样本是否符合某种分布(Goodeness of Fit Test)
- 检测两个变量是否独立（本文着重讨论相关性检测）&lt;/p&gt;

&lt;h3 id=&#34;卡方检验计算过程&#34;&gt;卡方检验计算过程&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;假设变量是独立的，没有相关性&lt;/li&gt;
&lt;li&gt;计算统计值：按照假设计算理论值，然后计算每一项的sqrt（实际值-理论值）/理论值，把所有的项都加起来&lt;/li&gt;
&lt;li&gt;自由度，（distinctCount(label)-1）x（distinctCount(feature)-1），可以用(行-1) x(列-1)来理解&lt;/li&gt;
&lt;li&gt;查表求p值，如果p值非常小（例如0.05），就拒绝假设&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;计算过程&#34;&gt;计算过程&lt;/h2&gt;

&lt;h3 id=&#34;举个例子&#34;&gt;举个例子&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt; val data = Seq(
      (0.0, Vectors.dense(0.5)),
      (0.0, Vectors.dense(0.5)),
      (1.0, Vectors.dense(1.5)),
      (0.0, Vectors.dense(3.5)),
      (2.0, Vectors.dense(3.5)),
      (1.0, Vectors.dense(1.5))
    )

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;统计每个维度取值和label的对应关系&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;th&gt;0.5&lt;/th&gt;
&lt;th&gt;1.5&lt;/th&gt;
&lt;th&gt;3.5&lt;/th&gt;
&lt;th&gt;总数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;合计&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;假设该维度和label是独立的，那么无论维度如何取值，取到的label为0的数目都是总数的1/2。&lt;/p&gt;

&lt;p&gt;维度取0.5的一共为2个，则理论上，0.5对应的label数目为1. 做出对应的表格如下：&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;label&lt;/th&gt;
&lt;th&gt;0.5&lt;/th&gt;
&lt;th&gt;1.5&lt;/th&gt;
&lt;th&gt;3.5&lt;/th&gt;
&lt;th&gt;总数&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
&lt;td&gt;&lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;合计&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;计算统计值为8&lt;/p&gt;

&lt;h3 id=&#34;验证统计值&#34;&gt;验证统计值&lt;/h3&gt;

&lt;p&gt;用Python验证：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
from scipy import stats
import fractions
obs = [2, 0, 1, 0, 2, 0, 0, 0, 1]
obs = [2, 0, 1, 0, 2, 0]
# 0, 2, 0, 0, 0, 1]
exp = [1, 1, 1,
       fractions.Fraction(2,3),fractions.Fraction(2,3), fractions.Fraction(2,3),
       fractions.Fraction(1,3),fractions.Fraction(1,3), fractions.Fraction(1,3)]

exp = [1, 1, 1,
       fractions.Fraction(2,3),fractions.Fraction(2,3), fractions.Fraction(2,3)]
       # fractions.Fraction(1,3),fractions.Fraction(1,3), fractions.Fraction(1,3)]

print(stats.chisquare(obs, f_exp = exp ,ddof=4))


obs= [0, 0, 1]
#exp= [fractions.Fraction(1,3),fractions.Fraction(1,3), fractions.Fraction(1,3)]
exp= [0.33333, 0.33333, 0.33333]

print(stats.chisquare(obs, f_exp = exp ))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;结果正确&lt;/p&gt;

&lt;h3 id=&#34;计算p值&#34;&gt;计算P值&lt;/h3&gt;

&lt;p&gt;//TODO&lt;/p&gt;

&lt;h3 id=&#34;验证结论&#34;&gt;验证结论&lt;/h3&gt;

&lt;p&gt;假设数据是这样子的：&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; val data = Seq(
      (0.0, Vectors.dense(0.5)),
      (0.0, Vectors.dense(0.5)),
      (1.0, Vectors.dense(1.5)),
      (1.0, Vectors.dense(1.5)),
      (2.0, Vectors.dense(3.5)),
      (2.0, Vectors.dense(3.5))
    )

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;肉眼可查，feature和label相关性很高。计算的P值为&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pValues = [0.017351265236664526]

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;这样理解：假如feature和label独立不相关的，只有1.7%的可能取到像样本这样的数据。所以假设不成立。&lt;/p&gt;

&lt;p&gt;参考：
&lt;a href=&#34;http://www.statisticshowto.com/probability-and-statistics/chi-square/&#34;&gt;http://www.statisticshowto.com/probability-and-statistics/chi-square/&lt;/a&gt;
&lt;a href=&#34;https://segmentfault.com/a/1190000003719712&#34;&gt;https://segmentfault.com/a/1190000003719712&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Databricks:Spark knowledge base</title>
      <link>https://lawulu.github.io/post/Databricks:Spark%20knowledge%20base/</link>
      <pubDate>Sat, 18 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lawulu.github.io/post/Databricks:Spark%20knowledge%20base/</guid>
      <description>

&lt;p&gt;内容来自：
&lt;a href=&#34;https://databricks.gitbooks.io/databricks-spark-knowledge-base/&#34;&gt;https://databricks.gitbooks.io/databricks-spark-knowledge-base/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;最佳实践&#34;&gt;最佳实践&lt;/h2&gt;

&lt;h3 id=&#34;避免使用groupbykey&#34;&gt;避免使用GroupByKey&lt;/h3&gt;

&lt;p&gt;在使用&lt;code&gt;groupByKey&lt;/code&gt;时候，Spark引擎并不清楚分组之后要做什么，所以无法在数据交换之前在Partition内部提前运算，而&lt;code&gt;reduceByKey&lt;/code&gt;不同，可以在分区内部提前调用&lt;code&gt;reduceByKey&lt;/code&gt;的&lt;code&gt;func&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&#34;不要将大数据量copy到driver中&#34;&gt;不要将大数据量Copy到Driver中&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;myVeryLargeRDD.collect()&lt;/code&gt;这句话会试图将所有数据都Copy到Driver中，导致内存溢出和程序崩溃。为查看数据，可以使用&lt;code&gt;take&lt;/code&gt;或者&lt;code&gt;takeSample&lt;/code&gt;，或者将数据写到文件或者数据库。&lt;/p&gt;

&lt;h3 id=&#34;优雅的处理错误数据&#34;&gt;优雅的处理错误数据&lt;/h3&gt;

&lt;p&gt;使用&lt;code&gt;map&lt;/code&gt;、&lt;code&gt;filter&lt;/code&gt;、&lt;code&gt;flatMap&lt;/code&gt;来过滤错误数据&lt;/p&gt;

&lt;h2 id=&#34;常规故障处理&#34;&gt;常规故障处理&lt;/h2&gt;

&lt;h3 id=&#34;task-not-serializable&#34;&gt;Task not serializable&lt;/h3&gt;

&lt;p&gt;这是因为堆对象只有在被序列化时候，才能在节点之间传递。解决办法:
- 实现序列化
- Declare the instance only within the lambda function passed in map.
- 将实例声明为static,这样在每个节点都会重新初始化
- 使用&lt;code&gt;rdd.forEachPartition&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;rdd.forEachPartition(iter -&amp;gt; {
     NotSerializable notSerializable = new NotSerializable();
   
     // ...Now process iter
   });
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;缺失依赖&#34;&gt;缺失依赖&lt;/h3&gt;

&lt;p&gt;解决办法：在 Maven 打包的时候创建 shaded 或 uber 任务，并将Spark的lib设为provided&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/troubleshooting/missing_dependencies_in_jar_files.html&#34;&gt;https://databricks.gitbooks.io/databricks-spark-knowledge-base/content/troubleshooting/missing_dependencies_in_jar_files.html&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;mac-error-running-start-all-sh-connection-refused&#34;&gt;Mac：Error running start-all.sh Connection refused&lt;/h3&gt;

&lt;p&gt;开启 “远程登录” 功能。进入 系统偏好设置 &amp;mdash;&amp;gt; 共享 勾选打开 远程登录。&lt;/p&gt;

&lt;h3 id=&#34;spark组件的网络连接问题&#34;&gt;Spark组件的网络连接问题&lt;/h3&gt;

&lt;h2 id=&#34;性能和优化&#34;&gt;性能和优化&lt;/h2&gt;

&lt;h3 id=&#34;rdd有多少个分区&#34;&gt;RDD有多少个分区？&lt;/h3&gt;

&lt;h4 id=&#34;使用-ui-查看在分区上执行的任务数&#34;&gt;使用 UI 查看在分区上执行的任务数&lt;/h4&gt;

&lt;h4 id=&#34;使用-ui-查看storage&#34;&gt;使用 UI 查看Storage&lt;/h4&gt;

&lt;h4 id=&#34;编程查看-rdd-分区&#34;&gt;编程查看 RDD 分区&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;scala&amp;gt; val someRDD = sc.parallelize(1 to 100, 30)
someRDD: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &amp;lt;console&amp;gt;:12

scala&amp;gt; someRDD.partitions.size
res0: Int = 30
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;数据本地性&#34;&gt;数据本地性&lt;/h3&gt;

&lt;p&gt;任务应该在离数据尽可能近的地方执行(例如最少的数据传输)。&lt;/p&gt;

&lt;h4 id=&#34;检查本地性&#34;&gt;检查本地性&lt;/h4&gt;

&lt;p&gt;注意UI中的&lt;code&gt;Locality Level&lt;/code&gt;&lt;/p&gt;

&lt;h4 id=&#34;调整本地性&#34;&gt;调整本地性&lt;/h4&gt;

&lt;p&gt;You can adjust how long Spark will wait before it times out on each of the phases of data locality (data local &amp;ndash;&amp;gt; process local &amp;ndash;&amp;gt; node local &amp;ndash;&amp;gt; rack local &amp;ndash;&amp;gt; Any)&lt;/p&gt;

&lt;h3 id=&#34;spark-streaming&#34;&gt;Spark Streaming&lt;/h3&gt;

&lt;h4 id=&#34;error-oneforonestrategy&#34;&gt;ERROR OneForOneStrategy&lt;/h4&gt;

&lt;p&gt;If you enable checkpointing in Spark Streaming, then objects used in a function called in forEachRDD should be Serializable. Otherwise, there will be an &amp;ldquo;ERROR OneForOneStrategy: &amp;hellip; java.io.NotSerializableException:&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>